<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[IDEA设置优化提高编程效率]]></title>
    <url>%2F2019%2F03%2F07%2FIDEA%E8%AE%BE%E7%BD%AE%E4%BC%98%E5%8C%96%E6%8F%90%E9%AB%98%E7%BC%96%E7%A8%8B%E6%95%88%E7%8E%87.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;idea现在已经成了java开发标配的ide，idea默认安装之后其默认的参数已经能够应对日常的大部分开发。这里主要记录下自己对此工具的一些参数的调整，以及快捷键的整理，提升自己编码效率(后续操作都是在mac下)。 常用参数设置GC算法堆内存修改IDEA默认安装之后采用的是CMS的GC算法，修改为G1算法，同一个配置文件中顺便修改堆内存大小,配置文件为bin/idea.vmoptions，修改如下参数: 1234567891011121314151617181920##设置堆内存大小，xms和xmx尽量设置同样大小-Xms1024m-Xmx1024m-XX:ReservedCodeCacheSize=240m-XX:+UseCompressedOops##解决windows下console中文乱码问题-Dfile.encoding=UTF-8## 修改gc算法-XX:+UseG1GC-XX:SoftRefLRUPolicyMSPerMB=50-ea-Dsun.io.useCanonCaches=false-Djava.net.preferIPv4Stack=true-Djdk.http.auth.tunneling.disabledSchemes=&quot;&quot;-XX:+HeapDumpOnOutOfMemoryError-XX:-OmitStackTraceInFastThrow-Xverify:none-XX:ErrorFile=$USER_HOME/java_error_in_idea_%p.log-XX:HeapDumpPath=$USER_HOME/java_error_in_idea.hprof 常用配置修改 自动编译 File | Settings | Build, Execution, Deployment | Compiler勾选 Build project automatically 忽略大小写开关(此开关不打开的话会导致某个关键词因为大小写而不智能提示) File | Settings | Editor | General | Code CompletionMatch Case 勾选框取消 悬浮提示(此设置可以使鼠标悬停的方法名给出jdoc) File | Settings | Editor | General勾选 Show quick documentation on mouse move 自动导入包去除 * 号 File | Settings | Editor | Code Style | Java &gt; importsClass count to user import with * 数字改大一点 Live Template设置利用Live Template设置自己的注释比如公司有自己的方法类的注释规范，平时自己写代码的注释格式，可以使用Live Template设置不同的注释， 设置方法： Settings&gt;Editor&gt;Live Templates: 点击右上角+号，新增Template Group，取名注释，再次点击+号，新增Live Template: 常用快捷键Command 快捷键 说明 Command+F 在当前文件进行文本查找 Command+R 在当前文件进行文本替换 Command+Z 撤销 Command+Y 删除光标所在行或者删除选中的行 Command+X 剪切光标所在行 或 剪切选择内容 Command+C 复制光标所在行 或 复制选择内容 Command+D 复制光标所在行 或 复制选择内容，并把复制内容插入光标位置下面 Command+W 递进式选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展选中范围 Command+E 显示最近打开的文件记录列表 Command+N 根据输入的类名查找类文件 Command+G 在当前文件跳转到指定处 Command+J 插入自定义动态代码模板 Command+P 方法参数提示 Command+Q 光标所在的变量/类名/方法名等上面（也可以在提示补充的时候按），显示文档内容 Command+U 前往当前光标所在的方法的父类的方法/接口的定义 Command+B 进入光标所在的方法/变量的接口或是定义出，等效于Command+左键单击 Command+K 版本控制提交项目，需要此项目有加入到版本控制才可用 Command+T 版本控制更新项目，需要此项目有加入到版本控制才可用 Command+H 显示当前类的层次结构 Command+O 选择可重写的方法 Command+I 选择可继承的方法 Command+ + 展开代码 Command+ - 折叠代码 Command+/ 注释光标所在行代码，会根据当前不同文件类型使用不同的注释符号 Command+[ 移动光标到当前所在代码的花括号开始位置 Command+] 移动光标到当前所在代码的花括号结束位置 Command+F1 在光标所在的错误代码处显示错误信息 Command+F3 跳转到所选中的词的下一个引用位置 Command+F4 关闭当前编辑文件 Command+F8 在 Debug 模式下，设置光标当前行为断点，如果当前已经是断点则去掉断点 Command+F9 执行 Make Project 操作 Command+F11 选中文件 / 文件夹，使用助记符设定 / 取消书签 （必备） Command+F12 弹出当前文件结构层，可以在弹出的层上直接输入，进行筛选 Command+Tab 编辑窗口切换，如果在切换的过程又加按上 delete，则是关闭对应选中的窗口 Command+End 跳到文件尾 Command+Home 跳到文件头 Command+Space 基础代码补全，默认在 Windows 系统上被输入法占用，需要进行修改，建议修改为 Command +逗号 （必备） Command+Delete 删除光标后面的单词或是中文句 （必备） Command+BackSpace 删除光标前面的单词或是中文句 （必备） Command+1,2,3…9 定位到对应数值的书签位置 （必备） Command+左键单击 在打开的文件标题上，弹出该文件路径 （必备） Command+光标定位 按 Command 不要松开，会显示光标所在的类信息摘要 Command+左方向键 光标跳转到当前单词 / 中文句的左侧开头位置 （必备） Command+右方向键 光标跳转到当前单词 / 中文句的右侧开头位置 （必备） Command+前方向键 等效于鼠标滚轮向前效果 （必备） Command+后方向键 等效于鼠标滚轮向后效果 （必备） Option 快捷键 说明 Option+` 显示版本控制常用操作菜单弹出层 （必备） Option+Q 弹出一个提示，显示当前类的声明 / 上下文信息 Option+F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择 （必备） Option+F2 对于前面页面，显示各类浏览器打开目标选择弹出层 Option+F3 选中文本，逐个往下查找相同文本，并高亮显示 Option+F7 查找光标所在的方法 / 变量 / 类被调用的地方 Option+F8 在 Debug 的状态下，选中对象，弹出可输入计算表达式调试框，查看该输入内容的调试结果 Option+Home 定位 / 显示到当前文件的 Navigation Bar Option+Enter IntelliJ IDEA 根据光标所在问题，提供快速修复选择，光标放在的位置不同提示的结果也不同（必备） Option+Insert 代码自动生成，如生成对象的 set / get 方法，构造函数，toString() 等（必备） Option+左方向键 切换当前已打开的窗口中的子视图，比如 Debug 窗口中有 Output、Debugger 等子视图，用此快捷键就可以在子视图中切换（必备） Option+右方向键 按切换当前已打开的窗口中的子视图，比如 Debug 窗口中有 Output、Debugger 等子视图，用此快捷键就可以在子视图中切换 （必备） Option+前方向键 当前光标跳转到当前文件的前一个方法名位置 （必备） Option+后方向键 当前光标跳转到当前文件的后一个方法名位置 （必备） Option+1,2,3…9 显示对应数值的选项卡，其中 1 是 Project 用得最多 （必备） SHIFT 快捷键 说明 Shift+F1 如果有外部文档可以连接外部文档 Shift+F2 跳转到上一个高亮错误 或 警告位置 Shift+F3 在查找模式下，查找匹配上一个 Shift+F4 对当前打开的文件，使用新 Windows 窗口打开，旧窗口保留 Shift+F6 对文件 / 文件夹 重命名 Shift+F7 在 Debug 模式下，智能步入。断点所在行上有多个方法调用，会弹出进入哪个方法 Shift+F8 在 Debug 模式下，跳出，表现出来的效果跟 F9 一样 Shift+F9 等效于点击工具栏的 Debug 按钮 Shift+F10 等效于点击工具栏的 Run 按钮 Shift+F11 弹出书签显示层 （必备） Shift+Tab 取消缩进 （必备） Shift+ESC 隐藏当前 或 最后一个激活的工具窗口 Shift+End 选中光标到当前行尾位置 Shift+Home 选中光标到当前行头位置 Shift+Enter 开始新一行。光标所在行下空出一行，光标定位到新行位置 （必备） Shift+左键单击 在打开的文件名上按此快捷键，可以关闭当前打开文件 （必备） Shift+滚轮前后滚动 当前文件的横向滚动轴滚动 （必备） Command+Option 快捷键 说明 Command+Option+L 格式化代码，可以对当前文件和整个包目录使用 （必备） Command+Option+O 优化导入的类，可以对当前文件和整个包目录使用 （必备） Command+Option+I 光标所在行 或 选中部分进行自动代码缩进，有点类似格式化 Command+Option+T 对选中的代码弹出环绕选项弹出层 （必备） Command+Option+J 弹出模板选择窗口，将选定的代码加入动态模板中 Command+Option+H 调用层次 Command+Option+B 在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口 Command+Option+V 快速引进变量 Command+Option+Y 同步、刷新 Command+Option+S 打开 IntelliJ IDEA 系统设置 （必备） Command+Option+F7 显示使用的地方。寻找被该类或是变量被调用的地方，用弹出框的方式找出来 Command+Option+F11 切换全屏模式 Command+Option+Enter 光标所在行上空出一行，光标定位到新行 （必备） Command+Option+Home 弹出跟当前文件有关联的文件弹出层 Command+Option+Space 类名自动完成 Command+Option+左方向键 退回到上一个操作的地方 （必备） Command+Option+右方向键 前进到上一个操作的地方 （必备） Command+Option+前方向键 在查找模式下，跳到上个查找的文件 Command+Option+后方向键 在查找模式下，跳到下个查找的文件 Command+SHIFT 快捷键 说明 Command+Shift+F 根据输入内容查找整个项目 或 指定目录内文件 （必备） Command+Shift+R 根据输入内容替换对应内容，范围为整个项目 或 指定目录内文件 （必备） Command+Shift+J 自动将下一行合并到当前行末尾 （必备） Command+Shift+Z 取消撤销 （必备） Command+Shift+W 递进式取消选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展取消选中范围 （必备） Command+Shift+N 通过文件名定位 / 打开文件 / 目录，打开目录需要在输入的内容后面多加一个正斜杠 （必备） Command+Shift+U 对选中的代码进行大 / 小写轮流转换 （必备） Command+Shift+T 对当前类生成单元测试类，如果已经存在的单元测试类则可以进行选择 （必备） Command+Shift+C 复制当前文件磁盘路径到剪贴板 （必备） Command+Shift+V 弹出缓存的最近拷贝的内容管理器弹出层 Command+Shift+E 显示最近修改的文件列表的弹出层 Command+Shift+H 显示方法层次结构 Command+Shift+B 跳转到类型声明处 （必备） Command+Shift+I 快速查看光标所在的方法 或 类的定义 Command+Shift+A 查找动作 / 设置 Command+Shift+/ 代码块注释 （必备） Command+Shift+[ 选中从光标所在位置到它的顶部中括号位置 （必备） Command+Shift+] 选中从光标所在位置到它的底部中括号位置 （必备） Command+Shift++ 展开所有代码 （必备） Command+Shift+- 折叠所有代码 （必备） Command+Shift+F7 高亮显示所有该选中文本，按 Esc 高亮消失 （必备） Command+Shift+F8 在 Debug 模式下，指定断点进入条件 Command+Shift+F9 编译选中的文件 / 包 / Module Command+Shift+F12 编辑器最大化 （必备） Command+Shift+Space 智能代码提示 Command+Shift+Enter 自动结束代码，行末自动添加分号 （必备） Command+Shift+ackspace 退回到上次修改的地方 （必备） Command+Shift+,2,3…9 快速添加指定数值的书签 （必备） Command+Shift+左键单击 把光标放在某个类变量上，按此快捷键可以直接定位到该类中 （必备） Command+Shift+左方向键 在代码文件上，光标跳转到当前单词 / 中文句的左侧开头位置，同时选中该单词 / 中文句（必备） Command+Shift+右方向键 在代码文件上，光标跳转到当前单词 / 中文句的右侧开头位置，同时选中该单词 / 中文句（必备） Command+Shift+前方向键 光标放在方法名上，将方法移动到上一个方法前面，调整方法排序 （必备） Command+Shift+后方向键 光标放在方法名上，将方法移动到下一个方法前面，调整方法排序 （必备） Option+SHIFT 快捷键 说明 Option+Shift+N 选择 / 添加 task （必备） Option+Shift+F 显示添加到收藏夹弹出层 / 添加到收藏夹 Option+Shift+C 查看最近操作项目的变化情况列表 Option+Shift+I 查看项目当前文件 Option+Shift+F7 在Debug 模式下，下一步，进入当前方法体内，如果方法体还有方法，则会进入该内嵌的方法中，依此循环进入 Option+Shift+F9 弹出 Debug 的可选择菜单 Option+Shift+F10 弹出 Run 的可选择菜单 Option+Shift+左键双击 选择被双击的单词 / 中文句，按住不放，可以同时选择其他单词 / 中文句 （必备） Option+Shift+前方向键 移动光标所在行向上移动 （必备） Option+Shift+后方向键 移动光标所在行向下移动 （必备） Command+SHIFT+Option 快捷键 说明 Command+Shift+Option+V 无格式黏贴 （必备） Command+Shift+Option+N 前往指定的变量 / 方法 Command+Shift+Option+S 打开当前项目设置 （必备） Command+Shift+Option+C 复制参考信息 OTHERS 快捷键 说明 F2 跳转到下一个高亮错误 或 警告位置 （必备） F3 在查找模式下，定位到下一个匹配处 F4 编辑源 （必备） F7 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该方法体还有方法，则不会进入该内嵌的方法中 F8 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则不进入当前方法体内 F9 在 Debug 模式下，恢复程序运行，但是如果该断点下面代码还有断点则停在下一个断点上 F11 添加书签 （必备） F12 回到前一个工具窗口 （必备） Tab缩进 （必备） ESC 从工具窗口进入代码文件窗口 （必备） 连按两次Shift 弹出 Search Everywhere 弹出层]]></content>
      <categories>
        <category>常用工具</category>
        <category>IDEA</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>IDEA优化</tag>
        <tag>IDEA快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker常用命令]]></title>
    <url>%2F2018%2F06%2F07%2FDocker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;docker为学习新知识提供了快速环境搭建的便捷，而且还能在不同的平台上实现一致的环境。下面是自己使用docker时的常用命令的总结 镜像操作获取镜像 1234docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签]#具体的选项可以通过 docker pull --help 命令看到，这里我们说一下镜像名称的格式。#Docker 镜像仓库地址：地址的格式一般是 &lt;域名/IP&gt;[:端口号]。默认地址是 Docker Hub。#仓库名：如之前所说，这里的仓库名是两段式名称，即 &lt;用户名&gt;/&lt;软件名&gt;。对于 Docker Hub，如果不给出用户名，则默认为 library，也就是官方镜像。 列出镜像 12345678910111213141516171819202122232425262728# 展示本地所有镜像docker image ls# 查看镜像、容器、数据卷所占用的空间docker system df# 查看悬虚镜像(仓库、标签名为&lt;none&gt;)docker image ls -f dangling=true# 查看中间层镜像docker image ls -a# 根据仓库名列出镜像docker image ls &lt;仓库名&gt; # 如 docker image ls ubuntu # 根据仓库名和标签列出镜像docker image ls # dockerhub搜索镜像docker search &lt;image_name&gt;# 下载镜像docker pull &lt;image_name&gt;# 删除一个或者多个镜像docker rmi &lt;image_name&gt;# 显示镜像的历史docker history &lt;image_name&gt;# 根据Dockerfile创建镜像docker build -t image_name:version contextPath # contextPath 上下文环境 创建时可以将上下文环境中的文件等拷贝到镜像中 容器常用命令123456789101112131415161718192021# 查看正在运行的容器docker ps# 用一行列出所有的容器docker ps | less -S# 查看所有的容器:docker ps -a# 查看最近启动的容器:docker ps -l# 查看运行状态容器里面的进程信息docker top &lt;container_name/container_id&gt;# 查看容器内容的详情docker inspect &lt;container_name/container_id&gt;# 保存容器docker commit old_container_id new_image_name# 删除单个容器docker rm &lt;container_name/container_id&gt;# 容器的停止、启动、杀死、重启docker stop &lt;name/id&gt;docker start &lt;name/id&gt;docker kill &lt;name/id&gt;docker restart &lt;name/id&gt; 网络常用命令1234# 查看docker0的网络(宿主机上操作)ip a show docker0# 查看容器的ip地址docker inspect -f '&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;' &lt;id、container_name&gt; docker-machine在单机测试模拟集群环境时,可以通过docker-machine来创建多个docker实例模拟集群,以下的操作都是在win10下通过hyperv驱动完成: 通过docker-machine创建单个docker实例 123456789101112docker-machine create -d hyperv #hyper-v创建的虚拟交换机--hyperv-virtual-switch=docker-machine \# 国内镜像代理--engine-registry-mirror https://registry.docker-cn.com \# 非第一次启动时,使用缓存的此镜像--hyperv-boot2docker-url ~/.docker/machine/cache/boot2docker.iso \# 控制单个docker实例内存--hyperv-memory 2048 \# 设置单个docker实例占用的cpu--hyperv-cpu-count 2 test 将创建的单个实例加入集群]]></content>
      <categories>
        <category>服务器</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录下自己linux中的常用命令]]></title>
    <url>%2F2018%2F06%2F07%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;linux是程序员时时打交道的操作系统，开发用的linux或类linux系统会有很友好的桌面端，但是在生产环境或者桌面版无法提供一些特殊功能时，通过linux命令去解决是一个很好的途径。下面是一些在开发中经常接触到的一些命令，和一些工具的使用的命令。 与系统有关的nohup&emsp;&emsp;nohup能让脚本或者程序在后台运行，避免满屏的日志或者退出命令行界面之后脚本或者程序停止运行。 语法: nohup command &gt; 输出重定向文件 如: nohup java -jar SpringBoot.jar &gt; $HOME/nohup.out ps&emsp;&emsp;ps命令用于报告系统当前进程状态，常用于查找当前系统是否在运行某程序； 语法 ps 如: ps -ef | grep java #查找当前系统进程中包含Java的进程 参数： 部分参数如下，查看完整参数参考 -a：显示所有终端机下执行的程序。-A：显示所有程序。-e：此选项的效果和指定”A”选项相同。e：列出程序时，显示每个程序所使用的环境变量。-f：显示UID,PPIP,C与STIME栏位。f：用ASCII字符显示树状结构，表达程序间的相互关系。 实例 ps -ef | grep java #查找当前系统中包含java关键字的进程信息 crontab&emsp;&emsp;系统级的定时任务； ip&emsp;&emsp;网络相关的操作 语法 参数： 实例 查看IP地址： ip addr]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记自己的一次vue之旅]]></title>
    <url>%2F2018%2F06%2F06%2F%E8%AE%B0%E8%87%AA%E5%B7%B1%E7%9A%84%E4%B8%80%E6%AC%A1vue%E4%B9%8B%E6%97%85.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;vue现在是越来越火，大有赶超react之势，在业余时间尝试了一次vue+element-ui开发前端项目，下面是自己的一些总结和踩过的坑。 基于element-ui和iview项目环境搭建&emsp;&emsp;vue官方提供了通过&lt;script&gt;直接引入，也可以通过vue-cli脚手架创建项目，这里以脚手架的方式来讲解，因此需要用到node环境. node安装在node官网找到自己系统对应的安装包，下载安装，然后配置环境变量和淘宝镜像: 123456# 查看node版本node --version# 查看npm版本npm --version# 设置淘宝镜像，用cnpm代替npmnpm install -g cnpm --registry=https://registry.npm.taobao.org element-ui搭建安装vue命令行工具 12345678910111213141516171819# 全局安装 vue-clinpm install -global vue-cli# 通过vue-cli初始化基于webpack模板的项目vue init webpack erp# 然后按照提示输入项目所需要的东西，router一定要有? Project name erp? Project description 物业管理软件? Author plaxj &lt;plaxj123@163.com&gt;? Vue build standalone? Install vue-router? Yes? Use ESLint to lint your code? Yes? Pick an ESLint preset Airbnb? Set up unit tests Yes? Pick a test runner karma? Setup e2e tests with Nightwatch? No? Should we run `npm install` for you after the project has been created? (recommended) npm# 然后是进入项目后通过cnpm install安装依赖的包 通过vue-cli搭建好项目的基本架子之后便是在项目中引入element-ui和iview配置项目根路径下的.babelrc文件: 123456789101112131415&#123; "presets": [ ["env", &#123; "modules": false, "targets": &#123; "browsers": ["&gt; 1%", "last 2 versions", "not ie &lt;= 8"] &#125; &#125;], "stage-2" ], "plugins": ["transform-vue-jsx", "transform-runtime",//配置jsx，element中有组件需要使用 ["import", &#123;"libraryName": "iview","libraryDirectory": "src/components"&#125;],// 配置iview ["component", [&#123;"libraryName": "element-ui", "styleLibraryName": "theme-chalk" &#125;]]// 配置element-ui ]&#125; 然后在命令端通过npm安装element-ui和iviewcnpm install element-ui --save cnpm install iview --save,由于在项目中还需要使用saas，less等，还需要安装less-loader、saas-loader等，只要启动的时候提示缺什么，然后安装即可，安装时注意如果只是开发时的依赖，添加--save-dev后缀 项目结构配置由于项目模块有多个，因此才有了模块分开独立开发，搭建了如下代码结构 1234567891011121314151617|-- build #build相关配置文件(配置多环境等)|-- config #各环境配置文件|-- src |-- utils #存放工具 |-- index.js #配置axios |-- common_utils.js #公用工具 |-- rules.js #各种验证 |-- assets #存放第三方js、css、字体等 |-- components #存放自己封装的组件 |-- constants #定义的常量枚举等 |-- router #各模块的路由 |-- store #vuex存放各模块数据 |-- views #各模块具体的视图文件 |-- App.vue #页面的入口 |-- main.js |-- main.less|-- static #图片等静态资源 axios的全局配置在src/utils/index.js中对通过axios请求后端做了一层统一的封装 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import axios from 'axios'import &#123; Message&#125; from 'element-ui'import router from '../router'export const Axios = axios.create(&#123; //项目需要部署到多个环境 baseURL: process.env.NODE_ENV === 'production' ? '生产环境后端api接口' : process.env.NODE_ENV === 'pre' ? '预生产环境后端api接口' : '', timeout: 10000, responseType: 'json', withCredentials: true, // 是否允许带cookie headers: &#123; 'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8' &#125;&#125;)// POST请求拦截 (对请求参数序列化)Axios.interceptors.request.use( config =&gt; &#123; // 对请求参数做加密 if (config.method === 'post' || config.method === 'get') &#123; // 请求参数加密逻辑 &#125; return config &#125;, error =&gt; &#123; Message(&#123; showClose: true, message: error, type: 'error' &#125;) return Promise.reject(error) &#125;)// 返回数据的判断校验Axios.interceptors.response.use( response =&gt; &#123; // 返回错误标志 if (response.data &amp;&amp; response.data.code !== '0') &#123; Message(&#123; showClose: true, message: response.data.msg, type: 'error' &#125;) return Promise.reject(new Error(response.data.msg)) &#125; return response &#125;, error =&gt; &#123; let requestData = eval('(' + error.response.config.data + ')') if (error.response.status === 404) &#123; // 404状态进行跳转 //router.push('404地址') &#125; else if (error.response.status === 500 || error.response.status === 400) &#123; // 400 或者500的处理逻辑 &#125; else &#123; // 返回 response 里的错误信息 return Promise.reject(error) &#125; &#125;)export default &#123; install: function (Vue, Option) &#123; Object.defineProperty(Vue.prototype, '$http', &#123; value: Axios &#125;) // 绑定到vue全局 后面可以通过this.$http.post/get('地址', &#123;参数跳用&#125;) &#125;&#125; router的配置路由也会做全局配置,通过在src/router/index.js中配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import Vue from 'vue'import Router from 'vue-router'import &#123;Message&#125; from 'element-ui'import 模块A from '模块A'Vue.use(Router)const router = new Router(&#123; routes: [ &#123; name: 'default',// 默认路由跳转到登录组件 path: '', component: resolve =&gt; require(['登录组件路径'], resolve) &#125;, &#123; name: 'login', path: '/login', component: resolve =&gt; require(['登录组件路径'], resolve) &#125;, &#123; name: '首页', path: '/index', redirect: '首页地址', component: resolve =&gt; require(['首页组件路径'], resolve), children: [ &#123; name: '404', path: '404', component: resolve =&gt; require(['404组件路径'], resolve) &#125;, &#123; name: '500', path: '500', component: resolve =&gt; require(['500组件路径'], resolve) &#125;, ...模块A ], meta: &#123; requiresAuth: true // 需要验证 &#125; &#125; ]&#125;)// 路由进入前判断是否需要鉴权 鉴权通过token来校验 包括存在、过期、合法等校验router.beforeEach((to, from, next) =&gt; &#123; if (to.matched.some(record =&gt; record.meta.requiresAuth)) &#123; if (条件) &#123; // 过期 合法性等校验逻辑 next() &#125; else &#123; Message(&#123; showClose: true, message: '登录状态过期,请重新登录!!', type: 'error' &#125;) next(&#123; path: '/login' &#125;) &#125; &#125; else &#123; // 确保一定要调用 next() next() &#125;&#125;)export default router 多环境配置项目中使用了三个环境：开发环境、测试环境和生产环境，调用的接口地址不一样，因此需要通过配置config和build下的文件来达到能通过命令参数来编译不同环境，其中测试环境和生产环境大致相同，都使用了vue-cli生成的配置文件，由于开发环境会遇到跨域问题：localhost请求后端地址时的跨域问题，需要在webpack的配置文件中做代理，在文件config/index.js中: 123456789101112131415dev: &#123; env: require('./dev.env'), port: process.env.PORT || 8080, autoOpenBrowser: true, assetsSubDirectory: 'static', assetsPublicPath: '/', proxyTable: &#123; '/接口请求路径': &#123; target: '后端api地址', // 你接口的域名 secure: false, // 如果是https接口，需要设置为true changeOrigin: true, // 如果接口跨域，需要进行这个参数配置 &#125; &#125;, cssSourceMap: false &#125;, 开发中的问题 多个请求需要同步 &emsp;&emsp;由于使用了axios请求后端,导致需要有先后顺序的多个请求同时发出，返回的数据没有了先后顺序，因此需要使用到es6中的await和async关键字和Promise一起，比如请求B需要A返回的结果: 12345678910111213// 后面的请求方法需要async修饰async function BRequest () &#123; let a_result = await ARequest(param) Axios.post('地址', &#123;a_result&#125;).then().error()&#125;function ARequest (param) &#123; return new Promise(resolve =&gt; &#123; Axios.post('请求地址', &#123;请求参数param&#125;).then(res =&gt; &#123; resolve(res.data...) &#125;).error() &#125;)&#125; 由于element-ui的form表单验证使用了异步，因此不能在this.$refs[&#39;form_name&#39;].validate()的验证方法中使用Promise，可以将Promise提出到验证外面 vue中注意点 v-if和v-show的区别:v-if条件成立时重新渲染组件，有生命周期的；v-show通过display:none控制 v-for需要指定key nodejs是单进程的，页面比较多的时执行cnpm run 命令加上参数--max_old_space_size=4096指定使用4G内存，避免编译报错 开发工具使用的visual studio code，很好用，但是项目依赖的包比较多的时候，git插件回去监听node_modules下所有的文件，会导致visual code越来越卡，解决的方法是修改配置文件，添加如下代码: 1234567891011121314151617181920// 解决vsc code helper占用cpu高的问题 "files.exclude": &#123; "**/.git": true, "**/.svn": true, "**/.hg": true, "**/CVS": true, "**/.DS_Store": true, "**/tmp": true, "**/node_modules": true, "**/bower_components": true, "**/dist": true &#125;, "files.watcherExclude": &#123; "**/.git/objects/**": true, "**/.git/subtree-cache/**": true, "**/node_modules/**": true, "**/tmp/**": true, "**/bower_components/**": true, "**/dist/**": true &#125;]]></content>
      <categories>
        <category>前端</category>
        <category>vue</category>
      </categories>
      <tags>
        <tag>vue常用配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA总结-单例]]></title>
    <url>%2F2018%2F05%2F11%2FJAVA%E6%80%BB%E7%BB%93-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;在平常开发中，我们会经常提供工具类，而工具类最常见的就是使用单例，其主要作用是确保一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。虽然单例模式最简单，但是在平常使用中需要注意到性能、线程安全等问题，下面介绍几种常见的单例模式实现方式： 单例模式懒汉式 当被问到单例模式，随手写出来估计就是懒汉式： 线程不安全:1234567891011121314public class LazySingleton&#123; private static LazySingleton singleton; private LazySingleton()&#123;&#125; public static LazySingleton getInstance()&#123; if(null == singleton)&#123; return new LazySingleton(); &#125; return singleton; &#125;&#125; 但是这种写法在多线程的情况下getInstance()会生成多个实例,并不能保证生成单例。 懒汉式(线程安全):1234567891011121314public class LazySingleton&#123; private static LazySingleton singleton; private LazySingleton()&#123;&#125; public static synchronized LazySingleton getInstance()&#123; if(null == singleton)&#123; return new LazySingleton(); &#125; return singleton; &#125;&#125; 双重校验锁模式上述方式虽然在多线程下保证了只能生成一个单例，但是性能不好，改为下面方式： 123456789101112131415161718public class LazySingleton &#123; public static volatile LazySingleton singleton; private LazySingleton()&#123;&#125; public static LazySingleton getNewInstance()&#123; if(null == singleton)&#123; synchronized (LazySingleton.class) &#123; if(null == singleton)&#123; singleton = new LazySingleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 这里使用volatile的原因是防止singleton = new LazySingleton()在JVM中指令重排序的优化 饿汉式饿汉式:12345678910public class HangerSingleton&#123; private static final HangerSingleton singleton = new HangerSingleton(); private HangerSingleton()&#123;&#125; public static getInstace()&#123; return singleton; &#125;&#125; 懒汉式和饿汉式的区别在于：饿汉式单例模式的类在加载时就实例化，而懒汉式单例在被调用取得实例方法的时候才会实例化对象; 静态内部类《Effective Java》上所推荐的静态内部类方式去实现 123456789101112131415public class StaticInnerClassSingleton &#123; private static class SingletonHolder &#123; private static final StaticInnerClassSingleton SINGLETON = new StaticInnerClassSingleton(); &#125; private StaticInnerClassSingleton() &#123; &#125; public static final StaticInnerClassSingleton getInstance() &#123; return SingletonHolder.SINGLETON; &#125;&#125; 枚举实现当然还可以使用枚举来实现单例： 1234567public enum EnumSingleton &#123; INSTANCE; public void otherMethod()&#123; System.out.println("Other Method"); &#125;&#125; 测试通过枚举实现的单例: 12345678910public class SingletonDemo &#123; public static void main(String[] args) &#123; EnumSingleton enumSingleton1 = EnumSingleton.INSTANCE; EnumSingleton enumSingleton2 = EnumSingleton.INSTANCE; enumSingleton1.otherMethod(); enumSingleton2.otherMethod(); System.out.println(enumSingleton1 == enumSingleton2); &#125;&#125; 输出： 123Other MethodOther Methodtrue 枚举实现的好处通过枚举实现的单例模式还有个好处是可以防止反射攻击和反序列化生成多个对象实例，然而饿汉式和懒汉式单例模式不采用特殊手段在类的序列化之后再反序列化会生成另外一个对象实例： 123456789public class Singleton implements Serializable&#123; private static final long serialVersionUID = 3594390482300477977L; private static final Singleton SINGLETON = new Singleton(); public Singleton()&#123;&#125; public static Singleton getInstance()&#123; return SINGLETON; &#125; &#125; 测试： 12345678910111213141516171819202122232425262728293031323334353637383940public class SingletonDemo &#123; public static void main(String[] args) &#123; Singleton singleton = Singleton.getInstance(); ObjectOutputStream oos = null; ObjectInputStream ois = null; try &#123; //序列化 oos = new ObjectOutputStream(new FileOutputStream(new File("object.out"))); oos.writeObject(singleton); //反序列化 ois = new ObjectInputStream(new FileInputStream(new File("object.out"))); Singleton newSingleton = (Singleton) ois.readObject(); System.out.println("序列化前的singleton对象的hashcode:"+singleton.hashCode()); System.out.println("反序列化后的singleton对象的hashcode:"+newSingleton.hashCode()); System.out.println(singleton == newSingleton); &#125; catch (IOException | ClassNotFoundException e) &#123; e.printStackTrace(); &#125;finally&#123; if(null != oos)&#123; try &#123; oos.close(); &#125; catch (IOException e) &#123; // &#125; &#125; if(null != ois)&#123; try &#123; oos.close(); &#125; catch (IOException e) &#123; // &#125; &#125; &#125; &#125;&#125; 输出： 123序列化前的singleton对象的hashcode:865113938反序列化后的singleton对象的hashcode:1442407170false 很明显反序列化后生成了新的singleton对象，而采用枚举类型实现的单例模式却没有： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class SingletonDemo &#123; public static void main(String[] args) &#123; EnumSingleton singleton = EnumSingleton.INSTANCE; ObjectOutputStream oos = null; ObjectInputStream ois = null; try &#123; //序列化 oos = new ObjectOutputStream(new FileOutputStream(new File("object.out"))); oos.writeObject(singleton); //反序列化 ois = new ObjectInputStream(new FileInputStream(new File("object.out"))); EnumSingleton newSingleton = (EnumSingleton) ois.readObject(); System.out.println("序列化前的singleton对象的hashcode:"+singleton.hashCode()); System.out.println("反序列化后的singleton对象的hashcode:"+newSingleton.hashCode()); System.out.println(singleton == newSingleton); &#125; catch (IOException | ClassNotFoundException e) &#123; e.printStackTrace(); &#125;finally&#123; if(null != oos)&#123; try &#123; oos.close(); &#125; catch (IOException e) &#123; // &#125; &#125; if(null != ois)&#123; try &#123; oos.close(); &#125; catch (IOException e) &#123; // &#125; &#125; &#125; &#125;&#125; 执行后输出：序列化前的singleton对象的hashcode:118352462反序列化后的singleton对象的hashcode:118352462true从上面可以看出通过枚举类型实现的单例模式不仅实现上简单，而且还能防止反射攻击和反序列化后的新对象实例的生成。其实除了枚举类型的单例模式，其他的单例模式实现也能防止反序列化生成新的实例，只需要添加一个readResolve方法即可: 123456789101112public class Singleton implements Serializable&#123; private static final long serialVersionUID = 3594390482300477977L; private static final Singleton SINGLETON = new Singleton(); public Singleton()&#123;&#125; public static Singleton getInstance()&#123; return SINGLETON; &#125; public Object readResolve()&#123; return SINGLETON; &#125;&#125; 再测试序列化和反序列化之后的情况： 12345678910111213141516171819202122232425262728293031323334353637383940public class SingletonDemo &#123; public static void main(String[] args) &#123; Singleton singleton = Singleton.getInstance(); ObjectOutputStream oos = null; ObjectInputStream ois = null; try &#123; //序列化 oos = new ObjectOutputStream(new FileOutputStream(new File("object.out"))); oos.writeObject(singleton); //反序列化 ois = new ObjectInputStream(new FileInputStream(new File("object.out"))); Singleton newSingleton = (Singleton) ois.readObject(); System.out.println("序列化前的singleton对象的hashcode:"+singleton.hashCode()); System.out.println("反序列化后的singleton对象的hashcode:"+newSingleton.hashCode()); System.out.println(singleton == newSingleton); &#125; catch (IOException | ClassNotFoundException e) &#123; e.printStackTrace(); &#125;finally&#123; if(null != oos)&#123; try &#123; oos.close(); &#125; catch (IOException e) &#123; // &#125; &#125; if(null != ois)&#123; try &#123; oos.close(); &#125; catch (IOException e) &#123; // &#125; &#125; &#125; &#125;&#125; 执行之后的结果： 123序列化前的singleton对象的hashcode:865113938反序列化后的singleton对象的hashcode:865113938true 可以看出序列化和反序列化都是对象的同一个实例，那为什么只加一个readResole方法就可解决问题呢？我们通过看ObjectInputStream源代码可以找到readObject()方法最后调用了readOrdinaryObject()方法： 1234567891011121314151617181920212223private Object readOrdinaryObject(boolean unshared) throws IOException &#123; //省略。。 if (obj != null &amp;&amp; handles.lookupException(passHandle) == null &amp;&amp; desc.hasReadResolveMethod()) &#123; Object rep = desc.invokeReadResolve(obj); if (unshared &amp;&amp; rep.getClass().isArray()) &#123; rep = cloneArray(rep); &#125; if (rep != obj) &#123; handles.setObject(passHandle, obj = rep); &#125; &#125; return obj; &#125; 观察上面代码我们可以看到readOrdinaryObject方法会去判断准备反序列化的类：如果实现了serializable或者externalizable接口，那么他是否包含readResolve方法，包含则通过反射的方式调用要被反序列化的类的readResolve方法。对应到前面的例子我们就可以知道ObjectInputStream在反序列化的时候调用了Singleton类的readResolve方法。当然除了上述3中单例模式的实现外，还有其他的比如：双重校验锁、静态内部类等实现方式，然后平常经常使用的还是饿汉式或者枚举类型实现的单例，除非明确要求类需要延迟加载的时候会使用懒汉式。那我们平时在使用的时候主要用于哪些场景呢,下面举了几个我目前理解的3个方面： 某个类需要频繁的创建和销毁; 频繁访问数据库或者文件; 初始化的时候耗时耗资源的类等;]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>单例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7 源码安装MySql5.7]]></title>
    <url>%2F2018%2F05%2F11%2FCentos7%20%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85Mysql5.7.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;在centos系统中，可以通过更新yum源来安装最新的mysql，也可以通过mysql官方的rmp包直接安装，但是这两种方式都不能在安装的时候自定义一些参数，只能安装后去修改文件，比如安装位置、数据存放路径、用户、端口、字符集等等。而通过源码编译安装却可以按照自己规划的配置去编译源码，安装的时候直接一步到位，还可以自由的选择特定的版本。下面是在64位centos7中安装mysql5.7.21的步骤 安装安装步骤 安装依赖环境 1yum -y install gcc gcc-c++ ncurses ncurses-devel cmake bison 获取mysql源码 123wget https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.21.tar.gz# 编译需要boostwget https://sourceforge.net/projects/boost/files/boost/1.59.0/boost_1_59_0.tar.gz 新建mysql用户和用户组 1groupadd -r mysql &amp;&amp; useradd -r -g mysql -s /sbin/nologin -M mysql 预编译 1234567891011121314cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql \ #程序安装目录-DMYSQL_DATADIR=/home/plaxj/mysql/data \ # 数据文件存放位置-DWITH_BOOST=/home/jack/software/boost_1_59_0 \ #所依赖的boost源码包位置-DSYSCONFDIR=/etc \-DWITH_INNOBASE_STORAGE_ENGINE=1 \-DWITH_PARTITION_STORAGE_ENGINE=1 \-DWITH_FEDERATED_STORAGE_ENGINE=1 \-DWITH_BLACKHOLE_STORAGE_ENGINE=1 \-DWITH_MYISAM_STORAGE_ENGINE=1 \-DENABLED_LOCAL_INFILE=1 \-DENABLE_DTRACE=0 \-DDEFAULT_CHARSET=utf8mb4 \-DDEFAULT_COLLATION=utf8mb4_general_ci \-DWITH_EMBEDDED_SERVER=1 编译安装 123make -j `grep processor /proc/cpuinfo | wc -l` #编译时采用的cpu核数make install 配置成系统服务 12345cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqldchmod +x /etc/init.d/mysqldsystemctl enable mysqld 配置my.cnf参数说明 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473# 以下选项会被MySQL客户端应用读取。# 注意只有MySQL附带的客户端应用程序保证可以读取这段内容。# 如果你想你自己的MySQL应用程序获取这些值。# 需要在MySQL客户端库初始化的时候指定这些选项。# For advice on how to change settings please see# http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html# *** DO NOT EDIT THIS FILE. It&apos;s a template which will be copied to the# *** default location during install, and will be replaced if you# *** upgrade to a newer version of MySQL.# mysqld程序[mysqld]# Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.# innodb_buffer_pool_size = 128M# ★★★这里很重要能让MySQL登陆链接变快速skip-name-resolve# Remove leading # to turn on a very important data integrity option: logging# changes to the binary log between backups.# log_bin# These are commonly set, remove the # and set as required.# 使用给定目录作为根目录(安装目录)。# basedir = .....# 从给定目录读取数据库文件。# datadir = .....# 为mysqld程序指定一个存放进程ID的文件(仅适用于UNIX/Linux系统);# pid-file = .....# 指定MsSQL侦听的端口# port = .....# server_id = .....# 为MySQL客户程序与服务器之间的本地通信指定一个套接字文件(Linux下默认是/var/lib/mysql/mysql.sock文件)# socket = .....user = jacksql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES# 一般配置选项basedir = /data/apps/mysqldatadir = /data/appData/mysqlport = 3306socket = /var/run/mysqld/mysqld.sock# 设置character-set-server=utf8# 指定MySQL可能的连接数量。# 当MySQL主线程在很短时间内接收到非常多的连接请求，该参数生效，主线程花费很短时间检查连接并且启动一个新线程。# back_log参数的值指出在MySQL暂时停止响应新请求之前的短时间内多少个请求可以被存在堆栈中。# 如果系统在一个短时间内有很多连接，则需要增大该参数的值，该参数值指定到来的TCP/IP连接的侦听队列的大小。# 试图设定back_log高于你的操作系统的限制将是无效的。默认值为50。对于Linux系统推荐设置为小于512的整数。# back_log 是操作系统在监听队列中所能保持的连接数,# 队列保存了在 MySQL 连接管理器线程处理之前的连接.# 如果你有非常高的连接率并且出现 “connection refused” 报错,# 你就应该增加此处的值.# 检查你的操作系统文档来获取这个变量的最大值.# 如果将back_log设定到比你操作系统限制更高的值，将会没有效果back_log = 300# 不在 TCP/IP 端口上进行监听.# 如果所有的进程都是在同一台服务器连接到本地的 mysqld,# 这样设置将是增强安全的方法# 所有 mysqld 的连接都是通过 Unix Sockets 或者命名管道进行的.# 注意在 Windows下如果没有打开命名管道选项而只是用此项# (通过 “enable-named-pipe” 选项) 将会导致 MySQL 服务没有任何作用!#skip-networking# MySQL 服务所允许的同时会话数的上限# 其中一个连接将被 SUPER 权限保留作为管理员登录.# 即便已经达到了连接数的上限.max_connections = 3000# 每个客户端连接最大的错误允许数量,如果达到了此限制.# 这个客户端将会被 MySQL 服务阻止直到执行了 “FLUSH HOSTS” 或者服务重启# 非法的密码以及其他在链接时的错误会增加此值.# 查看 “Aborted_connects” 状态来获取全局计数器.max_connect_errors = 50# 所有线程所打开表的数量.# 增加此值就增加了 mysqld 所需要的文件描述符的数量# 这样你需要确认在 [mysqld_safe] 中 “open-files-limit” 变量设置打开文件数量允许至少等于 table_cache 的值table_open_cache = 4096# 允许外部文件级别的锁. 打开文件锁会对性能造成负面影响# 所以只有在你在同样的文件上运行多个数据库实例时才使用此选项(注意仍会有其他约束!)# 或者你在文件层面上使用了其他一些软件依赖来锁定 MyISAM 表#external-locking# 服务所能处理的请求包的最大大小以及服务所能处理的最大的请求大小(当与大的 BLOB 字段一起工作时相当必要)# 每个连接独立的大小，大小动态增加max_allowed_packet = 32M# 在一个事务中 binlog 为了记录 SQL 状态所持有的 cache 大小# 如果你经常使用大的,多声明的事务,你可以增加此值来获取更大的性能.# 所有从事务来的状态都将被缓冲在 binlog 缓冲中然后在提交后一次性写入到 binlog 中# 如果事务比此值大, 会使用磁盘上的临时文件来替代.# 此缓冲在每个连接的事务第一次更新状态时被创建binlog_cache_size = 4M# 独立的内存表所允许的最大容量。# 此选项为了防止意外创建一个超大的内存表导致永尽所有的内存资源。max_heap_table_size = 128M# 随机读取数据缓冲区使用内存(read_rnd_buffer_size)：和顺序读取相对应，# 当 MySQL 进行非顺序读取（随机读取）数据块的时候，会利用&gt;这个缓冲区暂存读取的数据# 如根据索引信息读取表数据，根据排序后的结果集与表进行 Join 等等# 总的来说，就是当数据块的读取需要满足&gt;一定的顺序的情况下，MySQL 就需要产生随机读取，进而使用到 read_rnd_buffer_size 参数所设置的内存缓冲区read_rnd_buffer_size = 16M# 排序缓冲被用来处理类似 ORDER BY 以及 GROUP BY 队列所引起的排序# 如果排序后的数据无法放入排序缓冲,一个用来替代的基于磁盘的合并分类会被使用# 查看 “Sort_merge_passes” 状态变量。# 在排序发生时由每个线程分配# 每个需要进行排序的线程分配该大小的一个缓冲区。增加这值加速ORDER BY或GROUP BY操作。# 注意：该参数对应的分配内存是每连接独占！如果有100个连接，那么实际分配的总共排序缓冲区大小为100×6=600MBsort_buffer_size = 16M# 此缓冲被使用来优化全联合(FULL JOINS 不带索引的联合)。# 类似的联合在极大多数情况下有非常糟糕的性能表现,但是将此值设大能够减轻性能影响。# 通过 “Select_full_join” 状态变量查看全联合的数量# 当全联合发生时,在每个线程中分配join_buffer_size = 16M# 缓存可重用的线程数# thread_cache = 8# 避免MySQL的外部锁定，减少出错几率增强稳定性。# skip-locking # 我们在 cache 中保留多少线程用于重用# 当一个客户端断开连接后,如果 cache 中的线程还少于 thread_cache_size,则客户端线程被放入cache 中。# 这可以在你需要大量新连接的时候极大的减少线程创建的开销# (一般来说如果你有好的线程模型的话,这不会有明显的性能提升。)thread_cache_size = 16# 此允许应用程序给予线程系统一个提示在同一时间给予渴望被运行的线程的数量。# 此值只对于支持 thread_concurrency() 函数的系统有意义( 例如Sun Solaris)。# 你可可以尝试使用 [CPU数量]*(2..4) 来作为 thread_concurrency 的值#****(此属性对当前环境无效)****# thread_concurrency = 8# 查询缓冲常被用来缓冲 SELECT 的结果并且在下一次同样查询的时候不再执行直接返回结果。# 打开查询缓冲可以极大的提高服务器速度, 如果你有大量的相同的查询并且很少修改表。# 查看 “Qcache_lowmem_prunes” 状态变量来检查是否当前值对于你的负载来说是否足够高。# 注意: 在你表经常变化的情况下或者如果你的查询原文每次都不同,# 查询缓冲也许引起性能下降而不是性能提升。query_cache_size = 128M# 只有小于此设定值的结果才会被缓冲# 此设置用来保护查询缓冲,防止一个极大的结果集将其他所有的查询结果都覆盖。query_cache_limit = 4M# 被全文检索索引的最小的字长。# 你也许希望减少它，如果你需要搜索更短字的时候。# 注意在你修改此值之后，你需要重建你的 FULLTEXT 索引ft_min_word_len = 8# 如果你的系统支持 memlock() 函数，你也许希望打开此选项用以让运行中的 mysql 在在内存高度紧张的时候，数据在内存中保持锁定并且防止可能被 swapping out# 此选项对于性能有益#memlock# 当创建新表时作为默认使用的表类型，# 如果在创建表示没有特别执行表类型，将会使用此值#****(此属性对当前环境无效)****#default_table_type = InnoDB# 线程使用的堆大小. 此容量的内存在每次连接时被预留.# MySQL 本身常不会需要超过 64K 的内存# 如果你使用你自己的需要大量堆的 UDF 函数或者你的操作系统对于某些操作需要更多的堆，你也许需要将其设置的更高一点.thread_stack = 512K# 设定默认的事务隔离级别.可用的级别如下:# READ-UNCOMMITTED， READ-COMMITTED， REPEATABLE-READ， SERIALIZABLEtransaction_isolation = REPEATABLE-READ# 内部(内存中)临时表的最大大小# 如果一个表增长到比此值更大，将会自动转换为基于磁盘的表。# 此限制是针对单个表的，而不是总和。tmp_table_size = 128M# 打开二进制日志功能。# 在复制(replication)配置中，作为 MASTER 主服务器必须打开此项# 如果你需要从你最后的备份中做基于时间点的恢复，你也同样需要二进制日志。log-bin=mysql-bin# 如果你在使用链式从服务器结构的复制模式 (A-&gt;B-&gt;C)，# 你需要在服务器B上打开此项。# 此选项打开在从线程上重做过的更新的日志， 并将其写入从服务器的二进制日志。#log_slave_updates# 打开全查询日志。 所有的由服务器接收到的查询 (甚至对于一个错误语法的查询)# 都会被记录下来。 这对于调试非常有用， 在生产环境中常常关闭此项。#log# 将警告打印输出到错误 log 文件。 如果你对于 MySQL 有任何问题# 你应该打开警告 log 并且仔细审查错误日志，查出可能的原因。#log_warnings# 记录慢速查询。 慢速查询是指消耗了比 “long_query_time” 定义的更多时间的查询。# 如果 log_long_format 被打开，那些没有使用索引的查询也会被记录。# 如果你经常增加新查询到已有的系统内的话。 一般来说这是一个好主意，#log_slow_queries# 有的使用了比这个时间(以秒为单位)更多的查询会被认为是慢速查询。# 不要在这里使用“1″, 否则会导致所有的查询,甚至非常快的查询页被记录下来(由于 MySQL 目前时间的精确度只能达到秒的级别)。long_query_time = 6# 在慢速日志中记录更多的信息。# 一般此项最好打开。# 打开此项会记录使得那些没有使用索引的查询也被作为到慢速查询附加到慢速日志里#log_long_format# 此目录被MySQL用来保存临时文件。例如,# 它被用来处理基于磁盘的大型排序,和内部排序一样。# 以及简单的临时表。# 如果你不创建非常大的临时文件,将其放置到 swapfs/tmpfs 文件系统上也许比较好# 另一种选择是你也可以将其放置在独立的磁盘上。# 你可以使用”;”来放置多个路径# 他们会按照 roud-robin 方法被轮询使用。#tmpdir = /tmp# *** 主从复制相关的设置# 唯一的服务辨识号,数值位于 1 到 2^32-1之间。# 此值在master和slave上都需要设置。# 如果 “master-host” 没有被设置,则默认为1, 但是如果忽略此选项,MySQL不会作为master生效。server-id = 1# 复制的Slave (去掉master段的注释来使其生效)## 为了配置此主机作为复制的slave服务器,你可以选择两种方法:## 1) 使用 CHANGE MASTER TO 命令 (在我们的手册中有完整描述) -# 语法如下:## CHANGE MASTER TO MASTER_HOST=, MASTER_PORT=,# MASTER_USER=, MASTER_PASSWORD= ;## 你需要替换掉，等被尖括号包围的字段以及使用master的端口号替换 (默认3306)。## 例子:## CHANGE MASTER TO MASTER_HOST=’125.564.12.1′, MASTER_PORT=3306,# MASTER_USER=’joe’, MASTER_PASSWORD=’secret’;## 或者## 2) 设置以下的变量. 不论如何, 在你选择这种方法的情况下， 然后第一次启动复制(甚至不成功的情况下，# 例如如果你输入错密码在master-password字段并且slave无法连接)，# slave会创建一个 master.info 文件，并且之后任何对于包含在此文件内的参数的变化都会被忽略# 并且由 master.info 文件内的内容覆盖， 除非你关闭slave服务， 删除 master.info 并且重启slave 服务。# 由于这个原因，你也许不想碰一下的配置(注释掉的) 并且使用 CHANGE MASTER TO (查看上面) 来代替## 所需要的唯一id号位于 2 和 2^32 – 1之间# (并且和master不同)# 如果master-host被设置了.则默认值是2# 但是如果省略,则不会生效#server-id = 2## 复制结构中的master – 必须#master-host =## 当连接到master上时slave所用来认证的用户名 – 必须#master-user =## 当连接到master上时slave所用来认证的密码 – 必须#master-password =## master监听的端口.# 可选 – 默认是3306#master-port =# 使得slave只读。只有用户拥有SUPER权限和在上面的slave线程能够修改数据。# 你可以使用此项去保证没有应用程序会意外的修改slave而不是master上的数据#read_only#*** MyISAM 相关选项# 关键词缓冲的大小， 一般用来缓冲 MyISAM 表的索引块。# 不要将其设置大于你可用内存的30%，# 因为一部分内存同样被OS用来缓冲行数据# 甚至在你并不使用 MyISAM 表的情况下， 你也需要仍旧设置起 8-64M 内存由于它同样会被内部临时磁盘表使用。# key_buffer_size = 128M# 用来做 MyISAM 表全表扫描的缓冲大小.# 当全表扫描需要时,在对应线程中分配.# read_buffer_size = 8M# 当在排序之后,从一个已经排序好的序列中读取行时,行数据将从这个缓冲中读取来防止磁盘寻道.# 如果你增高此值,可以提高很多 ORDER BY 的性能.# 当需要时由每个线程分配# read_rnd_buffer_size = 64M# MyISAM 使用特殊的类似树的 cache 来使得突发插入# (这些插入是,INSERT … SELECT, INSERT … VALUES (…), (…), …, 以及 LOAD DATA INFILE) 更快.# 此变量限制每个进程中缓冲树的字节数.# 设置为 0 会关闭此优化.# 为了最优化不要将此值设置大于 “key_buffer_size”.# 当突发插入被检测到时此缓冲将被分配.# bulk_insert_buffer_size = 256M# 此缓冲当 MySQL 需要在 REPAIR, OPTIMIZE, ALTER 以及 LOAD DATA INFILE 到一个空表中引起重建索引时被分配.# 这在每个线程中被分配.所以在设置大值时需要小心.# myisam_sort_buffer_size = 256M# MySQL 重建索引时所允许的最大临时文件的大小 (当 REPAIR, ALTER TABLE 或者 LOAD DATA INFILE).# 如果文件大小比此值更大,索引会通过键值缓冲创建(更慢)# myisam_max_sort_file_size = 10G# 如果被用来更快的索引创建索引所使用临时文件大于制定的值,那就使用键值缓冲方法.# 这主要用来强制在大表中长字串键去使用慢速的键值缓冲方法来创建索引.# myisam_max_extra_sort_file_size = 10G# 如果一个表拥有超过一个索引, MyISAM 可以通过并行排序使用超过一个线程去修复他们.# 这对于拥有多个 CPU 以及大量内存情况的用户,是一个很好的选择.# myisam_repair_threads = 1# 自动检查和修复没有适当关闭的 MyISAM 表.# myisam_recover# 默认关闭 Federated# skip-federated# *** BDB 相关选项 ***# 如果你运行的MySQL服务有BDB支持但是你不准备使用的时候使用此选项. 这会节省内存并且可能加速一些事.#****(此属性对当前环境无效)****#skip-bdb# *** INNODB 相关选项 ***# 如果你的 MySQL 服务包含 InnoDB 支持但是并不打算使用的话,# 使用此选项会节省内存以及磁盘空间,并且加速某些部分#skip-innodb# 附加的内存池被 InnoDB 用来保存 metadata 信息(5.6中不再推荐使用)# 如果 InnoDB 为此目的需要更多的内存,它会开始从 OS 这里申请内存.# 由于这个操作在大多数现代操作系统上已经足够快, 你一般不需要修改此值.# SHOW INNODB STATUS 命令会显示当先使用的数量.#****(此属性对当前环境无效)****#innodb_additional_mem_pool_size = 64M# InnoDB使用一个缓冲池来保存索引和原始数据, 不像 MyISAM.# 这里你设置越大,这能保证你在大多数的读取操作时使用的是内存而不是硬盘,在存取表里面数据时所需要的磁盘 I/O 越少.# 在一个独立使用的数据库服务器上,你可以设置这个变量到服务器物理内存大小的80%# 不要设置过大,否则,由于物理内存的竞争可能导致操作系统的换页颠簸.# 注意在32位系统上你每个进程可能被限制在 2-3.5G 用户层面内存限制,# 所以不要设置的太高.innodb_buffer_pool_size = 6G# InnoDB 将数据保存在一个或者多个数据文件中成为表空间.# 如果你只有单个逻辑驱动保存你的数据,一个单个的自增文件就足够好了.# 其他情况下.每个设备一个文件一般都是个好的选择.# 你也可以配置 InnoDB 来使用裸盘分区 – 请参考手册来获取更多相关内容innodb_data_file_path = ibdata1:10M:autoextend# 设置此选项如果你希望InnoDB表空间文件被保存在其他分区.# 默认保存在MySQL的datadir中.#innodb_data_home_dir =# 用来同步IO操作的IO线程的数量.# 此值在Unix下被硬编码为8,但是在Windows磁盘I/O可能在一个大数值下表现的更好.#innodb_file_io_threads = 8# 如果你发现 InnoDB 表空间损坏, 设置此值为一个非零值可能帮助你导出你的表.# 从1开始并且增加此值知道你能够成功的导出表.#innodb_force_recovery=1# 在 InnoDb 核心内的允许线程数量.# 最优值依赖于应用程序,硬件以及操作系统的调度方式.# 过高的值可能导致线程的互斥颠簸.innodb_thread_concurrency = 16# 如果设置为1 ,InnoDB 会在每次提交后刷新(fsync)事务日志到磁盘上,# 这提供了完整的 ACID 行为.# 如果你愿意对事务安全折衷, 并且你正在运行一个小的事物, 你可以设置此值到0或者2来减少由事务日志引起的磁盘I/O# 0代表日志只大约每秒写入日志文件并且日志文件刷新到磁盘.# 2代表日志写入日志文件在每次提交后,但是日志文件只有大约每秒才会刷新到磁盘上.innodb_flush_log_at_trx_commit = 2#（说明：如果是游戏服务器，建议此值设置为2；如果是对数据安全要求极高的应用，建议设置为1；#设置为0性能最高，但如果发生故障，数据可能会有丢失的危险！#默认值1的意思是每一次事务提交或事务外的指令都需要把日志写入（flush）硬盘，这是很费时的。#特别是使用电池供电缓存（Battery backed up cache）时。#设成2对于很多运用，特别是从MyISAM表转过来的是可以的，它的意思是不写入硬盘而是写入系统缓存。#日志仍然会每秒flush到硬盘，所以你一般不会丢失超过1-2秒的更新。#设成0会更快一点，但安全方面比较差，即使MySQL挂了也可能会丢失事务的数据。而值2只会在整个操作系统挂了时才可能丢数据。）# 加速 InnoDB 的关闭. 这会阻止 InnoDB 在关闭时做全清除以及插入缓冲合并.# 这可能极大增加关机时间, 但是取而代之的是 InnoDB 可能在下次启动时做这些操作.#innodb_fast_shutdown# 用来缓冲日志数据的缓冲区的大小.# 当此值快满时, InnoDB 将必须刷新数据到磁盘上.# 由于基本上每秒都会刷新一次,所以没有必要将此值设置的太大(甚至对于长事务而言)innodb_log_buffer_size = 16M# 在日志组中每个日志文件的大小.# 你应该设置日志文件总合大小到你缓冲池大小的25%~100%# 来避免在日志文件覆写上不必要的缓冲池刷新行为.# 不论如何, 请注意一个大的日志文件大小会增加恢复进程所需要的时间.innodb_log_file_size = 512M# 在日志组中的文件总数.# 通常来说2~3是比较好的.innodb_log_files_in_group = 3# InnoDB 的日志文件所在位置. 默认是 MySQL 的 datadir.# 你可以将其指定到一个独立的硬盘上或者一个RAID1卷上来提高其性能#innodb_log_group_home_dir# 在 InnoDB 缓冲池中最大允许的脏页面的比例.# 如果达到限额, InnoDB 会开始刷新他们防止他们妨碍到干净数据页面.# 这是一个软限制,不被保证绝对执行.innodb_max_dirty_pages_pct = 90# InnoDB 用来刷新日志的方法.# 表空间总是使用双重写入刷新方法# 默认值是 “fdatasync”, 另一个是 “O_DSYNC”.# 一般来说，如果你有硬件 RAID 控制器，并且其独立缓存采用 write-back 机制，并有着电池断电保护，那么应该设置配置为 O_DIRECT# 否则，大多数情况下应将其设为 fdatasync#innodb_flush_method=fdatasync# 在被回滚前,一个 InnoDB 的事务应该等待一个锁被批准多久.# InnoDB 在其拥有的锁表中自动检测事务死锁并且回滚事务.# 如果你使用 LOCK TABLES 指令, 或者在同样事务中使用除了 InnoDB 以外的其他事务安全的存储引擎# 那么一个死锁可能发生而 InnoDB 无法注意到.# 这种情况下这个 timeout 值对于解决这种问题就非常有帮助.innodb_lock_wait_timeout = 120# 这项设置告知InnoDB是否需要将所有表的数据和索引存放在共享表空间里（innodb_file_per_table = OFF） 或者为每张表的数据单独放在一个.ibd文件（innodb_file_per_table = ON）# 每张表一个文件允许你在drop、truncate或者rebuild表时回收磁盘空间# 这对于一些高级特性也是有必要的，比如数据压缩,但是它不会带来任何性能收益innodb_file_per_table = on[mysqldump]# 不要在将内存中的整个结果写入磁盘之前缓存. 在导出非常巨大的表时需要此项quickmax_allowed_packet = 32M[mysql]no-auto-rehashdefault-character-set=utf8# 仅仅允许使用键值的 UPDATEs 和 DELETEs .safe-updates[myisamchk]key_buffer = 16Msort_buffer_size = 16Mread_buffer = 8Mwrite_buffer = 8M[mysqlhotcopy]interactive-timeout[mysqld_safe]# 增加每个进程的可打开文件数量.# 警告: 确认你已经将全系统限制设定的足够高!# 打开大量表需要将此值设大open-files-limit = 8192## MySQL 服务端#[client]default-character-set=utf8 配置环境变量 1echo -e &apos;\n\nexport PATH=/usr/local/mysql/bin:$PATH\n&apos; &gt;&gt; /etc/profile &amp;&amp; source /etc/profile 初始化数据库 1mysqld --initialize-insecure --user=jack --basedir=/usr/local/mysql --datadir=/home/jack/mysql/data 启动数据库 1systemctl start mysqld 配置数据库root密码 12mysql_secure_installation# 一路选择y(密码强度选择1 数字+大小写+特殊字符) 允许远程访问 123456# 用root登录mysqlmysql -uroot -p# 授权远程访问grant all privileges on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;pwd&apos;;flush privileges; 命令行工具MyCli 是一个 MySQL 命令行工具，支持自动补全和语法高亮。也可用于 MariaDB 和 Percona。安装MyCli： 12# 在 Mac OS X 中安装brew update &amp;&amp; brew install mycli 使用方式： 1$ mycli [OPTIONS] [DATABASE] 主要参数： -h, –host TEXT 数据库的主机地址。 -P, –port INTEGER 用于连接的端口号。 Honors $MYSQL_TCP_PORT -u, –user TEXT 连接到数据库的用户名。 -S, –socket TEXT 用于连接的套接字文件。 -p, –password TEXT 连接到数据库的密码。 –pass TEXT 连接到数据库的密码。 -v, –version mycli的版本输出。 -D, –database TEXT 使用数据库。 -R, –prompt TEXT 提示格式 (Default: “\t \u@\h:\d&gt; “) -l, –logfile FILENAME 将每一个查询和它的结果记录到一个文件中。 –defaults-group-suffix TEXT 读取指定的后缀的配置组。 –defaults-file PATH 只从给定文件中读取默认选项。 –auto-vertical-output 如果结果比终端更宽，自动切换到垂直输出模式。 –login-path TEXT 从登录文件中读取此路径。 –help 显示此帮助消息 使用例子: 1mycli -h url -u username database 导入导出导入将备份数据sql文件通过source命令导入： 导入前准备 如果sql文件中包含大量的insert into语句，可以通过sed替换成INSERT DELAYED INTO 1sed &apos;s/INSERT INTO/INSERT DELAYED INTO/g&apos; /路径/filename.sql 修改my.cnf配置: 1234#1、禁用索引(InnoDB不用)#2、禁用binlog#3、修改innodb_flush_log_at_trx_commit=0导入完成后这些配置都需要改回来 导入sql文件 123456789# 登录数据库mysql -uroot -p#如果只是导入到某个数据库mysql&gt; use dbname;# 设置字符编码mysql&gt; set names utf8;#导入数据库文件mysql&gt; source /路径/filename.sql]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解memcached存储机制]]></title>
    <url>%2F2018%2F05%2F04%2F%E7%BC%93%E5%AD%98%E4%B9%8Bmemcached-%E7%90%86%E8%A7%A3memcached%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6.html</url>
    <content type="text"><![CDATA[在使用memcached之后，我们有可能在思考，为什么对于我们放进memcached的数据，它是怎样在内存中存放的呢。根据文档可以知道目前memcached默认情况下采用了Slab Allocator数据存储方式，其原理主要是根据设定的memcached内存大小以及slab配置的大小，将memcached的内存划分为不同的slab，然后将slab分割成不同的块，大致的过程如下图： 那memcached服务器是如何存储客户端请求的数据呢？memcached会根据收到的数据大小，选择最适合数据大小的slab去存储，memcached保存着slab中空闲的chunk信息，然后选择合适的chunk去存储数据。具体的过程如下: 虽然这种存储方式避免了内存碎片，但是也造成了内存的空间的浪费 因此在平时的使用中，我们需要根据具体的热点数据的大小，去调整f参数的大小，减少内存的浪费.]]></content>
      <categories>
        <category>缓存</category>
        <category>memcached</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[memcached的分布式算法以及java客户端的开发]]></title>
    <url>%2F2018%2F05%2F03%2F%E7%BC%93%E5%AD%98%E4%B9%8Bmemcached-memcached%E7%9A%84java%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BC%80%E5%8F%91.html</url>
    <content type="text"><![CDATA[在前面的文章中主要介绍了memcached的安装和常见命令以及存储的过程，但是在实际的开发中，我们更多的使用memcached的客户端sdk进行数据的缓存操作。memcached为多种语言都提供了相应的客户端sdk，下面以java作为演示。memcached的客户端有很多，包括memcached自己提供的memcached client for java和Dustin Sallings实现的基于java nio的Spymemcached以及xmemcached。memcached同样是基于nio实现，由于其文档比较丰富，现在以xmemcached为演示。 在pom.xml中引入最新的xmemcached依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.googlecode.xmemcached&lt;/groupId&gt; &lt;artifactId&gt;xmemcached&lt;/artifactId&gt; &lt;version&gt;2.2.0&lt;/version&gt;&lt;/dependency&gt; xmemcached常用api：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146 public class MemcachedDemo &#123; private static final String SERVER_ADDR = "192.168.1.4:11211"; private static final String SERVER_ADDRS = "92.168.1.4:11211 192.168.1.50:11211 192.168.1.51:11211"; private static MemcachedClient client; public static void initConn() throws IOException &#123; MemcachedClientBuilder builder = new XMemcachedClientBuilder(AddrUtil.getAddresses(SERVER_ADDR)); client = builder.build(); &#125; /** *xmemcached自带分布式系统中的一致性hash算法 */ public static void initConsistentHashConn() throws IOException&#123; MemcachedClientBuilder builder = new XMemcachedClientBuilder(AddrUtil.getAddresses(SERVER_ADDRS)); builder.setSessionLocator(new KetamaMemcachedSessionLocator()); client = builder.build(); &#125; public static void closeConn() &#123; if (null != client) &#123; try &#123; client.shutdown(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) throws Exception &#123; initConn(); String key01 = "PPSS:PROD:100001010"; /*********************** data operattion ***************************/ //set boolean isStored = client.set(key01, 0, 100); System.out.println("set new key---&gt;"+isStored); //get System.out.println("get key---&gt;"+client.get(key01)); //delete System.out.println("delete key---&gt;"+client.delete(key01)); //get System.out.println("get key---&gt;"+client.get(key01)); //set conn time out(unit:s) System.out.println(client.set(key01, 1, 150, 5)); //update key expire time System.out.println("update key expire time----&gt;"+client.touch(key01, 0)); //add System.out.println("add exist key:key01 ----&gt;"+client.add(key01, 0, 223));//false System.out.println("add new key:key10 ---&gt;"+client.add("key10", 0, 22));//true System.out.println("get key10---&gt;"+client.get("key10")); //replace System.out.println("replace key:key10 ----&gt;"+client.replace("key10", 0, 33));//true System.out.println("get key:key10---&gt;"+client.get("key10")); System.out.println("replace not exist key:key05---&gt;"+client.replace("key05", 0, 100));//false //gets System.out.println("gets key:key10"+client.gets("key10")); //incr System.out.println("incr price ---&gt;"+client.incr("price01", 20, 100)); System.out.println("get incr price---&gt;"+client.get("price01")); //decr System.out.println("set price decr---&gt;"+client.decr("price01", 20)); System.out.println("get decr price---&gt;"+client.get("price01")); //client CAS GetsResponse&lt;Integer&gt; result = client.gets("price01"); long cas = result.getCas(); if(!client.cas("price01", 0, 200, cas))&#123; System.err.println("cas error"); &#125; System.out.println("get cas price---&gt;"+client.get("price01")); //client CAS client.cas("price01", 0,new CASOperation&lt;Integer&gt;() &#123; /* (non-Javadoc) * @see net.rubyeye.xmemcached.CASOperation#getMaxTries() */ @Override public int getMaxTries() &#123; //try how many times return 10; &#125; /* (non-Javadoc) * @see net.rubyeye.xmemcached.CASOperation#getNewValue(long, java.lang.Object) */ @Override public Integer getNewValue(long currentCAS, Integer currentValue) &#123; //the cache value will updated by return int return 256; &#125; &#125;); System.out.println("cas price01 ---&gt;"+client.get("price01")); //append client.set("name01", 0, "zhangsan"); System.out.println("append key:name01---&gt;"+client.append("name01", "!!")); System.out.println("get key:name01---&gt;"+client.get("name01")); //prepend System.out.println("prepend key:name01---&gt;"+client.prepend("name01", "hello ")); System.out.println("get key:name01---&gt;"+client.get("name01")); //cache domain User zhangsan = new User(); zhangsan.setName("zhangsan"); zhangsan.setAge(20); zhangsan.setSex(0); client.set("USER:zhangsan", 0, zhangsan); User cacheUser = client.get("USER:zhangsan"); System.out.println("cache user zhangsan--&gt;"+"name:"+cacheUser.getName()+" age:"+cacheUser.getAge()+" sex:"+(cacheUser.getSex()==0?"男":"女")); closeConn(); //consistent hash initConsistentHashConn(); System.out.println("set key:PROD:1000101:DESC---&gt;"+client.set("PROD:1000101:DESC", 0, "this production is very good!")); System.out.println("get key:PROD:1000101:DESC---&gt;"+client.get("PROD:1000101:DESC"));//data found at 192.168.1.51 System.out.println("set key:PROD:1000101:NAME---&gt;"+client.set("PROD:1000101:NAME", 0, "apple 7 plus")); System.out.println("get key:PROD:1000101:NAME---&gt;"+client.get("PROD:1000101:NAME"));//data found at 192.168.1.50 closeConn(); &#125;&#125; User.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class User implements Serializable&#123; private static final long serialVersionUID = 1L; private String name; private int age; private int sex; /** * @return the name */ public String getName() &#123; return name; &#125; /** * @param name the name to set */ public void setName(String name) &#123; this.name = name; &#125; /** * @return the age */ public int getAge() &#123; return age; &#125; /** * @param age the age to set */ public void setAge(int age) &#123; this.age = age; &#125; /** * @return the sex */ public int getSex() &#123; return sex; &#125; /** * @param sex the sex to set */ public void setSex(int sex) &#123; this.sex = sex; &#125;&#125; 与spring的集成 pom.xml中引入spring的依赖,spring配置文件中增加: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;bean id="memcachedBuilder" class="net.rubyeye.xmemcached.XMemcachedClientBuilder"&gt;&lt;!-- 添加memcached服务器 --&gt; &lt;constructor-arg&gt; &lt;list&gt; &lt;bean class="java.net.InetSocketAddress"&gt; &lt;constructor-arg&gt; &lt;value&gt;192.168.1.4&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;1211&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class="java.net.InetSocketAddress"&gt; &lt;constructor-arg&gt; &lt;value&gt;192.168.1.50&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;11211&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class="java.net.InetSocketAddress"&gt; &lt;constructor-arg&gt; &lt;value&gt;192.168.1.51&lt;/value&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;value&gt;11211&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;/list&gt; &lt;/constructor-arg&gt; &lt;!-- 设置服务器的权重 --&gt; &lt;constructor-arg&gt; &lt;list&gt; &lt;value&gt;1&lt;/value&gt; &lt;value&gt;2&lt;/value&gt; &lt;value&gt;1&lt;/value&gt; &lt;/list&gt; &lt;/constructor-arg&gt; &lt;property name="connectionPoolSize" value="2"&gt;&lt;/property&gt; &lt;property name="commandFactory"&gt; &lt;bean class="net.rubyeye.xmemcached.command.TextCommandFactory"&gt;&lt;/bean&gt; &lt;/property&gt; &lt;!-- 一致性hash --&gt; &lt;property name="sessionLocator"&gt; &lt;bean class="net.rubyeye.xmemcached.impl.KetamaMemcachedSessionLocator"&gt;&lt;/bean&gt; &lt;/property&gt; &lt;property name="transcoder"&gt; &lt;bean class="net.rubyeye.xmemcached.transcoders.SerializingTranscoder" /&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="memcachedClient" factory-bean="memcachedBuilder" factory-method="build" destroy-method="shutdown"/&gt; 简单演示数据操作： 12345678910111213141516171819202122232425 public class MemcachedClientBySpring &#123; public static void main(String[] args) throws Exception &#123; ApplicationContext ac = new ClassPathXmlApplicationContext("spring.xml"); MemcachedClient client = (MemcachedClient) ac.getBean("memcachedClient"); //set System.out.println("set key:key100---&gt;"+client.set("key100", 0, "key100")); System.out.println("get key:key100---&gt;"+client.get("key100")); //cache domain User lisi = new User(); lisi.setName("lisi"); lisi.setAge(30); lisi.setSex(0); client.set("USER:lisi", 0, lisi); User cacheUser = client.get("USER:lisi"); System.out.println("cache user---&gt;"+"name:"+cacheUser.getName()+" age:"+cacheUser.getAge()+" sex:"+(cacheUser.getSex()==0?"男":"女")); &#125;&#125; 其他API详情请参考xmemcached中文用户指南]]></content>
      <categories>
        <category>缓存</category>
        <category>memcached</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[memcached常用命令]]></title>
    <url>%2F2018%2F05%2F02%2F%E7%BC%93%E5%AD%98%E4%B9%8Bmemcached-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html</url>
    <content type="text"><![CDATA[memcached常用命令memcached交互协议主要有文本协议和二进制协议，其中二进制协议会比文本协议略快。文本协议主要包含在执行item的命令过程中，其中item命令有两行，第一行:$$\langle command name \rangle \langle key \rangle \langle flags \rangle \langle exptime \rangle \langle bytes \rangle $$ 12345command name:如 set add replace等key:唯一标识flags:32位的标志值，存储关于键值对的额外信息exptime:键值对缓存时间，单位为秒，0为永久（实际最多30天）bytes:数据大小 第二行：value，存储的值常用命令包括数据存储、读取等命令： 数据存储set:数据存在时更新，数据不存在存储12345678910111213141516171819202122#连接到memcached服务端telnet 192.168.1.4 11211#存储数据，永不失效set key1 0 0 4testSTOREDset key1 0 0 5test1STOREDset key1 0 0 4test2ERROR#指定失效时间:10sset price 0 10 451.5get priceEND#超过10s，存储的数据没了 add:当数据不存在时存储123456789101112add name 0 0 10zhangsan STOREDadd name 0 0 10lisiNOT_STOREDget name VALUE name 0 10zhangsanEND replace:当数据存在时替换之前的数据存储12345678910111213set address 0 0 100china sichuanSTOREDreplace address 0 0 100china chongqingSTOREDdelete addressreplace address 0 0 100china yunnanNOT_STORED 数据读取get:key可以多个，多个key之间空格12345678910get key1VALUE key1 0 5test1ENDget key1 nameVALUE key1 0 5test1VALUE name 0 10zhangsan gets:与get相同，但是会多返回一个数字，判断数据是否被修改过，相当于版本控制12345678910111213gets key1VALUE key1 0 5 4test1ENDset key1 0 0 5plaxjSTOREDgets key1VALUE key1 0 5 7plaxjEND cas:check and set 多线程中的同步操作。主要用于多个客户端同时读取的事后保证原子操作。当最后一个参数与gets返回的数字一致时才存储，否则返回EXISTS。12345678910111213141516171819gets key1 VALUE key1 0 5 7plaxjENDcas key1 0 0 5 5 6 CLIENT_ERROR bad data chunkERRORgets key1VALUE key1 0 5 8plaxjENDcas key1 0 0 5 8test1STOREDget key1VALUE key1 0 5test1END 数字的加减incr:增加12345678910set price 0 180 4 20STOREDincr price 1030get priceVALUE price 0 430 END decr:减少12345678910get priceVALUE price 0 430 ENDdecr price 525get priceVALUE price 0 425 END 追加与清除命令append:追加到已经存在的数据之后，当存在时才会存储123456789101112131415get key1VALUE key1 0 5test1ENDappend key1 0 0 5plaxjSTOREDget key1VALUE key1 0 10test1plaxjENDappend key10 0 0 1011NOT_STORED prepend:追加到已经存在的数据之前，当存在时才会存储123456789101112131415get key1VALUE key1 0 10test1plaxjENDprepend key1 0 0 4 lisiSTOREDget key1VALUE key1 0 14lisitest1plaxjENDprepend key10 0 0 10123NOT_STORED delete:删除缓存数据，数据存在时，删除成功返回DELETED，不存在时返回NOT_FOUND12345678910get key1 VALUE key1 0 14lisitest1plaxjENDdelete key1DELETEDget key1ENDdelete key10NOT_FOUND flush_all:将当前所有缓存数据设置为过期，不释放内存.1234flush_allOKget key1END 其他命令stats:返回memcached服务器状态信息12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061statsSTAT pid 7161STAT uptime 362695STAT time 1481369769STAT version 1.4.33STAT libevent 2.0.22-stableSTAT pointer_size 64STAT rusage_user 76.234473STAT rusage_system 114.678044STAT curr_connections 10STAT total_connections 16STAT connection_structures 11STAT reserved_fds 20STAT cmd_get 30STAT cmd_set 19STAT cmd_flush 1STAT cmd_touch 0STAT get_hits 22STAT get_misses 8STAT get_expired 1STAT get_flushed 0STAT delete_misses 1STAT delete_hits 3STAT incr_misses 0STAT incr_hits 0STAT decr_misses 0STAT decr_hits 0STAT cas_misses 0STAT cas_hits 2STAT cas_badval 0STAT touch_hits 0STAT touch_misses 0STAT auth_cmds 0STAT auth_errors 0STAT bytes_read 1188STAT bytes_written 1177STAT limit_maxbytes 67108864STAT accepting_conns 1STAT listen_disabled_num 0STAT time_in_listen_disabled_us 0STAT threads 4STAT conn_yields 0STAT hash_power_level 16STAT hash_bytes 524288STAT hash_is_expanding 0STAT malloc_fails 0STAT log_worker_dropped 0STAT log_worker_written 0STAT log_watcher_skipped 0STAT log_watcher_sent 0STAT bytes 80STAT curr_items 1STAT total_items 11STAT expired_unfetched 0STAT evicted_unfetched 0STAT evictions 0STAT reclaimed 0STAT crawler_reclaimed 0STAT crawler_items_checked 0STAT lrutail_reflocked 0END 返回的字段中部分解释: 名称 含义 pid server端的pid uptime 自启动到现在的时间(秒) time 当前服务器时间 version 版本号 libevent 当前memcached服务器依赖的libevent版本 pointer_size 指针大小 curr_items 当前已经存储的item数目 rusage_user 该进程累计的用户时间，单位：秒 rusage_system 该进程累计的系统时间，单位：秒 curr_items Memcached 当前存储的内容数量 total_items 服务端从启动到现在总共存储的item数量 bytes 存储item花费的内存大小 curr_connections 当前客户端连接数量 total_connections 服务端从启动到现在总共的连接数 connection_structures 分配的链接数 cmd_get get次数 cmd_set set的次数 get_his get命中次数 get_misses get未命中次数 evictions 为新的item释放内存空间而被移除的有效item的数目。如果cache的size比较小，则淘汰策略经常发生 bytes_read 从cache中读取的总字节数 bytes_written 写入cache的总字节数 limit_maxbytes server分配的最大内存数量 stats items:查看items行123456789101112131415stats itemsSTAT items:1:number 1STAT items:1:age 2537STAT items:1:evicted 0STAT items:1:evicted_nonzero 0STAT items:1:evicted_time 0STAT items:1:outofmemory 0STAT items:1:tailrepairs 0STAT items:1:reclaimed 0STAT items:1:expired_unfetched 0STAT items:1:evicted_unfetched 0STAT items:1:crawler_reclaimed 0STAT items:1:crawler_items_checked 0STAT items:1:lrutail_reflocked 0END stats cachedump slabs_id limit_num和上面的stats items结合查看具体的item命令:slabs_id:上面stats items返回的STAT items后面的数字limit_num:返回几条记录，0:所有记录 123stats cachedump 1 0ITEM name [10 b; 0 s]END stats slabs:返回各个slab的信息:chunk的大小、数目、使用情况123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051STAT 1:chunk_size 96STAT 1:chunks_per_page 10922STAT 1:total_pages 1STAT 1:total_chunks 10922STAT 1:used_chunks 1STAT 1:free_chunks 10921STAT 1:free_chunks_end 0STAT 1:mem_requested 80STAT 1:get_hits 20STAT 1:cmd_set 17STAT 1:delete_hits 1STAT 1:incr_hits 0STAT 1:decr_hits 0STAT 1:cas_hits 2STAT 1:cas_badval 0STAT 1:touch_hits 0STAT 2:chunk_size 120STAT 2:chunks_per_page 8738STAT 2:total_pages 1STAT 2:total_chunks 8738STAT 2:used_chunks 0STAT 2:free_chunks 8738STAT 2:free_chunks_end 0STAT 2:mem_requested 0STAT 2:get_hits 2STAT 2:cmd_set 2STAT 2:delete_hits 2STAT 2:incr_hits 0STAT 2:decr_hits 0STAT 2:cas_hits 0STAT 2:cas_badval 0STAT 2:touch_hits 0STAT 4:chunk_size 192STAT 4:chunks_per_page 5461STAT 4:total_pages 1STAT 4:total_chunks 5461STAT 4:used_chunks 0STAT 4:free_chunks 5461STAT 4:free_chunks_end 0STAT 4:mem_requested 0STAT 4:get_hits 0STAT 4:cmd_set 0STAT 4:delete_hits 0STAT 4:incr_hits 0STAT 4:decr_hits 0STAT 4:cas_hits 0STAT 4:cas_badval 0STAT 4:touch_hits 0STAT active_slabs 3STAT total_malloced 3145584END stats sizes:所有的item的大小和个数stats reset 清空所有统计数据stats系列命令能够为我们清晰的提供的memcached服务器的运行状态，我们可以通过这些命令组合去监控分布式memcached服务器的运行情况，及时的处理问题和提出需要优化的地方等。]]></content>
      <categories>
        <category>缓存</category>
        <category>memcached</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存之memcached-安装和基本配置]]></title>
    <url>%2F2018%2F05%2F01%2F%E7%BC%93%E5%AD%98%E4%B9%8Bmemcached-%E5%AE%89%E8%A3%85%E5%92%8C%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE.html</url>
    <content type="text"><![CDATA[当应用系统面对高并发调用或者访问的时候，优化应对的方式有很多，将部分数据缓存是个有效的方式之一，目前常用的开源缓存解决方案有很多，memcached是最早开始接触的缓存，下面演示下memcached的搭建过程和常用配置。下面的演示都是基于centos7环境下： memcached的安装 memcached安裝需要libevent，先安装libevent: 123456789101112wget http://cloud.github.com/downloads/libevent/libevent/libevent-2.0.17-stable.tar.gz tar -zxvf libevent-2.0.17-stable.tar.gzcd libevent-2.0.17-stable/./configure --prefix=/usr/local/libevent &amp;&amp; make &amp;&amp; make install #指定libevent编译安装的目录，后面memcached安装需要&#123;% endcodeblock %&#125;然后安装memcached：&#123;% codeblock lang:shell %&#125;wget http://memcached.org/files/memcached-1.4.33.tar.gztar -zxvf memcached-1.4.33.tar.gzcd memcached-1.4.33/./configure --with-libevent=/usr/local/libevent &amp;&amp; make &amp;&amp; make install 启动参数：123456789101112-P 监听的TCP端口，缺省为11211-U 监听的UDP端口，缺省为11211，0表示关闭-l 绑定监听的地址 -d 以daemon方式运行-u 运行memcached的账户，非root账户-m 使用的最大内存，单位是MB，缺省为64MB-M 分配的内存用完返回错误，禁止LRU-c 连接数量，缺省为1024-P 当以daemon方式运行时，保存pid到指定的文件中-f 块大小增长因子，默认1.25-n 最小分配空间，key+value+flags默认是48byte-I 每个slab page的大小 启动memcached: 123memcached -d -m 256 -p 11211 -u root -c 25 -l 192.168.1.4 -P /var/run/memcached.pidmemcached -d -m 256 -p 11211 -u root -c 25 -l 192.168.1.5 -P /var/run/memcached.pidmemcached -d -m 256 -p 11211 -u root -c 25 -l 192.168.1.6 -P /var/run/memcached.pid memcached的监控 平时在使用memcached的时候我们需要对它进行监控，比如我们需要知道当前的memcached的状态，命中率，内存使用情况等，如果有多个服务器，来回切换比较麻烦，因此可以通过memcachedPHP来监控memcached 在centos下简单安装: 1234567891011121314151617181920212223242526272829#安装apacheyum -y install httpd #安装apachechkconfig httpd on #配置开机自启动service httpd start #启动apacheyum -y install httpd-manual mod_ssl mod_perl mod_auth_mysql #安装apache扩展模块#关闭防火墙，在浏览器中输入http://ip即可看到httpd安装成功#安装phpyum -y install php php-mysqlyum -y install gd php-gd gd-devel php-xml php-common php-mbstring php-ldap php-pear php-xmlrpc php-imap#安装memcachedPHPcd /var/www/html/wget http://pecl.php.net/get/memcache-3.0.8.tgztar zxvf memcache-3.0.8.tgzcd memcache-3.0.8vi memcache.php$VERSION='$Id: memcache.php 326707 2012-07-19 19:02:42Z ab $';define('ADMIN_USERNAME','admin'); // 管理员帐号define('ADMIN_PASSWORD','admin'); // 管理员密码define('DATE_FORMAT','Y/m/d H:i:s');define('GRAPH_SIZE',200);define('MAX_ITEM_DUMP',50);$MEMCACHE_SERVERS[] = '192.168.1.4:11211'; // 添加memcached 服务器IP和端口$MEMCACHE_SERVERS[] = '192.168.1.5:11211'; // 添加memcached 服务器IP和端口$MEMCACHE_SERVERS[] = '192.168.1.6:11211'; // 添加memcached 服务器IP和端口]]></content>
      <categories>
        <category>缓存</category>
        <category>memcached</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA总结-捕获Thread中run方法抛出的异常]]></title>
    <url>%2F2017%2F05%2F11%2FJAVA%E6%80%BB%E7%BB%93-%E6%8D%95%E8%8E%B7%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%ADrun%E6%96%B9%E6%B3%95%E6%8A%9B%E5%87%BA%E7%9A%84%E5%BC%82%E5%B8%B8.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;线程运行中可能抛出异常，而run()方法又不提供throws关键字，可以通过实现Thread的UncaughtExceptionHandler接口来注册到线程上抓到异常。 12345678910111213141516171819202122public class ThreadsDemo02&#123; public static void main(String[] args)&#123; Thread t = new Thread(new Runnable()&#123; @Override public void run()&#123; int num = Integer.parseInt("hello"); &#125; &#125;); t.setName("error_thread"); t.setUncaughtExceptionHandler(new MyThreadUncaughtException()); t.start(); &#125;&#125;class MyThreadUncaughtException implements UncaughtExceptionHandler&#123; @Override public void uncaughtException(Thread t,Throwable e)&#123; System.out.println("Thread's Name:"+t.getName()+",exception:"+e.getMessage()); &#125;&#125;output:Thread's Name:error_thread,exception:For input string: "hello"]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>线程异常</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA总结-四舍五入与保留位]]></title>
    <url>%2F2017%2F05%2F11%2FJAVA%E6%80%BB%E7%BB%93-%E5%9B%9B%E8%88%8D%E4%BA%94%E5%85%A5%E4%B8%8E%E4%BF%9D%E7%95%99%E4%BD%8D.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;在最近的项目中，同事在做报表统计订单金额相关的问题时，由于数据类型采用了float，在最后统计对账时始终和财务相差几毛钱，然后我看了下代码，发现是四舍五入的问题，在此再根据网上的资料再学习下java中的四舍五入与保留位。 Math类的四舍五入函数 java在四舍五入计算时，可以使用Math类提供的函数实现四舍五入： Math.round() Math.round():Returns the closest long to the argument, with ties rounding to positive infinity.返回最接近入参的整数： 123456789public static void main(String[] args) &#123; double n = 2.4, i = 2.5,j = -2.3,k = -2.6; System.out.println("2.4 round四舍五入："+Math.round(n)); System.out.println("2.5 round四舍五入："+Math.round(i)); System.out.println("-2.3 round四舍五入："+Math.round(j)); System.out.println("-2.6 round四舍五入："+Math.round(k)); &#125; output: 12342.4 round四舍五入：22.5 round四舍五入：3-2.3 round四舍五入：-2-2.6 round四舍五入：-3 Math.floor() Math.floor():Returns the largest (closest to positive infinity) double value that is less than or equal to the argument and is equal to a mathematical integer.返回小于或者等于入参的整数,向下取整。 123456789public static void main(String[] args) &#123; double n = 2.4, i = 2.5,j = -2.3,k = -2.6; System.out.println("2.4 floor四舍五入："+Math.floor(n)); System.out.println("2.5 floor四舍五入："+Math.floor(i)); System.out.println("-2.3 floor四舍五入："+Math.floor(j)); System.out.println("-2.6 floor四舍五入："+Math.floor(k)); &#125; output: 12342.4 floor四舍五入：2.02.5 floor四舍五入：2.0-2.3 floor四舍五入：-3.0-2.6 floor四舍五入：-3.0 Math.ceil() Math.ceil():Returns the smallest (closest to negative infinity) double value that is greater than or equal to the argument and is equal to a mathematical integer.返回大于或者等于入参的整数,向上取整。 123456789public static void main(String[] args) &#123; double n = 2.4, i = 2.5,j = -2.3,k = -2.6; System.out.println("2.4 ceil四舍五入："+Math.ceil(n)); System.out.println("2.5 ceil四舍五入："+Math.ceil(i)); System.out.println("-2.3 ceil四舍五入："+Math.ceil(j)); System.out.println("-2.6 ceil四舍五入："+Math.ceil(k)); &#125; output: 12342.4 ceil四舍五入：3.02.5 ceil四舍五入：3.0-2.3 ceil四舍五入：-2.0-2.6 ceil四舍五入：-2.0 四舍五入的同时保留有效位数由于Math类提供的四舍五入函数只能保留到整数，当我们想保留多少位小数的时候就得采用如下方式了： 1234567public static void main(String[] args) &#123; double a=20.1554; System.out.println("保留两位小数:"+Math.round(a*100.0)/100.0); System.out.println("保留3位小数:"+Math.round(a*1000.0)/1000.0); &#125; output: 12保留两位小数:20.16保留3位小数:20.155 float/double精度误差 在使用float和double的时候，往往会产生精度损失，如下面的例子(double类型)：0.09 + 0.01=0.1?10.0125 * 100=1001.25?3.03 / 100=0.0303?然而实际的输出值:0.099999999999999991001.24999999999990.030299999999999997因此在使用float和double的计算中可能会出现精度的损失，造成最终结果的误差 BigDecimal与RoundingModeRoundingMode 在采用Math.round()方法实现四舍五入的话，在计算金额方面特别是银行业务上，会与专业的财务计算方式产生误差，通过下面的简单例子说明：比如现在有10笔存款，产生的利息为100.000、100.001、100.002、100.003、100.004、100.005、100.006、100.007、100.008、100.009，如果按照以往的四舍五入的方法的话，在结算给客户的时候(加入保留两位):0.001、0.002、0.003、0.004舍去，五入部分：0.005、0.004、0.003、0.002、0.001，则对于这10笔利息，银行实际的收支为：0.001+0.002+0.003+0.004-0.005-0.004-0.003-0.002-0.001=-0.005，银行亏0.005，虽然金额小，但是银行的业务量巨大，也会产生很大的误差，那么用什么方法来解决呢？ 美国的银行家提出了四舍六入五取偶（又称四舍六入五留双）法，即当舍去位的数值小于5时，直接舍去该位；当舍去位的数值大于等于6时，在舍去该位的同时向前位进一；当舍去位的数值等于5时，如果前位数值为奇，则在舍去该位的同时向前位进一，如果前位数值为偶，则直接舍去该位。如：100.001～100.004都会舍去，100.006～100.009都会五入，100.005由于舍去位为5，前位为偶数，因此舍去。因此对于这10笔存款的利息最后银行收支为：0.001+0.002+0.003+0.004+0.005-0.004-0.003-0.002-0.001=0.005，这样会少付0.005的利息 123456789101112131415public static void main(String[] args) &#123; // double 类型 double storeMoney = 100000.00; double interest = 0.002512453;// 一个月利率 double total = Math.round(storeMoney * interest*100.0)/100.0; System.out.println("利息：" + total); // BigDecimal BigDecimal storeMoneyTotal = new BigDecimal("100000.00"); BigDecimal newInterest = new BigDecimal("0.002512353"); System.out.println("利息：" + storeMoneyTotal.multiply(newInterest).setScale(2, RoundingMode.HALF_EVEN));//银行家舍入法 &#125; output: 12利息：251.25利息：251.24 RoundingMode提供的四舍五入类型： ROUND_UP：远离零方向舍入。向绝对值最大的方向舍入，只要舍弃位非0即进位。 ROUND_DOWN：趋向零方向舍入。向绝对值最小的方向输入，所有的位都要舍弃，不存在进位情况。 ROUND_CEILING：向正无穷方向舍入。向正最大方向靠拢。若是正数，舍入行为类似于ROUND_UP，若为负数，舍入行为类似于ROUND_DOWN。Math.round()方法就是使用的此模式。 ROUND_FLOOR：向负无穷方向舍入。向负无穷方向靠拢。若是正数，舍入行为类似于ROUND_DOWN；若为负数，舍入行为类似于ROUND_UP。 HALF_UP：最近数字舍入(5进)。这是我们最经典的四舍五入。 HALF_DOWN：最近数字舍入(5舍)。在这里5是要舍弃的。 HAIL_EVEN：银行家舍入法。BigDecimal&nbsp;&nbsp;&nbsp;&nbsp;BigDecimal是Java提供的一个不变的、任意精度的有符号十进制数对象。它提供了四个构造器，有两个是用BigInteger构造，在这里我们不关心，我们重点看用double和String构造的两个构造器（有关BigInteger详细介绍请查阅j2se API文档）。BigDecimal(double)是把一个double类型十进制数构造为一个BigDecimal对象实例。BigDecimal(String)是把一个以String表示的BigDecimal对象构造为BigDecimal对象实例。习惯上，对于浮点数我们都会定义为double或float，但BigDecimal API文档中对于BigDecimal(double)有这么一段话：Note: the results of this constructor can be somewhat unpredictable. One might assume that new BigDecimal(.1) is exactly equal to .1, but it is actually equal to .10000000000000000555111512312578 27021181583404541015625. This is so because .1 cannot be represented exactly as a double (or, for that matter, as a binary fraction of any finite length). Thus, the long value that is being passed in to the constructor is not exactly equal to .1, appearances notwithstanding.The (String) constructor, on the other hand, is perfectly predictable: new BigDecimal(“.1”) is exactly equal to .1, as one would expect. Therefore, it is generally recommended that the (String) constructor be used in preference to this one下面对这段话做简单解释：注意：这个构造器的结果可能会有不可预知的结果。有人可能设想new BigDecimal(.1)等于.1是正确的，但它实际上是等于.1000000000000000055511151231257827021181583404541015625，这就是为什么.1不能用一个double精确表示的原因，因此，这个被放进构造器中的长值并不精确的等于.1，尽管外观看起来是相等的。然而（String）构造器，则完全可预知的，newBigDecimal(“.1”)如同期望的那样精确的等于.1，因此，（String）构造器是被优先推荐使用的。看下面的结果： System.out.println(new BigDecimal(123456789.02).toString()); System.out.println(new BigDecimal(“123456789.02”).toString());输出为： 01999999582767486572265625 02现在我们知道，如果需要精确计算，非要用String来够造BigDecimal不可！常用BigDecimal与RoundingMode结合使用，如：1234567public static void main(String[] args) &#123; BigDecimal storeMoney = new BigDecimal("100000.00");//存入金额 BigDecimal newInterest = new BigDecimal("0.002512353");//月利率 System.out.println("利息：" + storeMoney.multiply(newInterest).setScale(2, RoundingMode.HALF_EVEN));//银行家舍入法,保留2位小数 &#125;]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>四舍五入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx的安装]]></title>
    <url>%2F2017%2F05%2F11%2Fnginx%E5%AE%89%E8%A3%85.html</url>
    <content type="text"><![CDATA[&emsp;&emsp;nginx是一个性能强大，稳定和功能完善的服务器，能提供譬如：web服务器、静态网页服务器、反向代理、压缩、缓存、负载均衡等等功能，可以通过第三方的模块去扩展更多的功能。在目前的大型互联网公司，基本都是在使用nginx。下面根据nginx官网指导教程通过源码安装在centos7上搭建自己的nginx服务器。 安装nginx依赖&nbsp;&nbsp;&nbsp;&nbsp;nginx源码编译需要gcc、pcre、Gzip和OpenSSL等。gcc通过centos自带的yum安装。其他软件默认安装到/usr/local/目录下： c/c++编译器安装12yum -y install gccyum -y install gcc-c++ pcre安装12345wget https://ftp.pcre.org/pub/pcre/pcre-8.42.tar.gztar -zxf pcre-8.40.tar.gzcd pcre-8.40./configure --prefix=/usr/local/make &amp;&amp; make install zlib安装12345wget http://zlib.net/zlib-1.2.11.tar.gztar -zxf zlib-1.2.11.tar.gzcd zlib-1.2.11./configure --prefix=/usr/local/make &amp;&amp; make install openssl安装12345wget https://www.openssl.org/source/openssl-1.1.1c.tar.gztar -zxf openssl-1.0.2f.tar.gzcd openssl-1.0.2f./config --prefix=/usr/local/make &amp;&amp; make install 下载源码&nbsp;&nbsp;&nbsp;&nbsp;nginx提供了开发版本和稳定版本，开发版本包含最新的功能，但是可能会有bug。本机搭建的nginx使用的是稳定版本。 1234cd /usr/localwget http://nginx.org/download/nginx-1.16.1.tar.gztar zxf nginx-1.16.1.tar.gzcd nginx-1.16.1 配置编译选项，例如： 1234567891011$ ./configure--sbin-path=/usr/local/nginx/nginx--conf-path=/usr/local/nginx/nginx.conf--pid-path=/usr/local/nginx/nginx.pid--with-pcre=../pcre-8.42--with-zlib=../zlib-1.2.11--with-http_ssl_module--with-stream--with-mail=dynamic--add-module=/usr/build/nginx-rtmp-module--add-dynamic-module=/usr/build/3party_module 常用编译选项 名称 作用 –prefix=path 将nginx编译到哪个目录,默认编译到/usr/local/nginx –sbin-path=path 执行文件存放的目录，默认编译到prefix/sbin/nginx –conf-path=path 配置文件存放路径，默认编译到prefix/conf/nginx.conf –pid-path=path 设置主进程的进程ID文件存放路径，默认编译到prefix/logs/nginx.pid，可以后期通过nginx.conf修改 –error-log-path=path 错误日志文件路径，默认编译到prefix/logs/error.log，可以后期通过nginx.conf修改 –http-log-path=path http请求日志路径，默认编译到prefix/logs/access.log，可以后期通过nginx.conf修改 –user=name 设置运行nginx worker 进程的用户，默认是 nobody，可以后期通过nginx.conf修改 –group=name 设置nginx进程的用户组，可以后期通过nginx.conf user命令修改 –with-pcre=path pcre lib的位置，nginx.conf的location指令的正则表达式和ngx_http_rewrite_module模块需要pcre的支持 其他的请查看官方指导文档 常用nginx模块&nbsp;&nbsp;&nbsp;&nbsp;在编译nginx源码时，可以通过–with命令来指定需要的模块，也可以用–without来排除默认指定的模块,例如： 1./configure --sbin-path=/usr/local/nginx/nginx --conf-path=/usr/local/nginx/nginx.conf --pid-path=/usr/local/nginx/nginx.pid --with-http_ssl_module --with-stream --with-pcre=../pcre-8.40 --with-zlib=../zlib-1.2.11 --without-http_empty_gif_module 常见模块如下： 模块名称 作用 http_charset_module 设置响应头部Content-Type字段，可以将数据从一种编码转换到另外一种编码 http_gzip_module 通过gzip压缩响应数据，能够减少传输数据一半以上 http_proxy_module 代理模块 http_upstream_keepalive_module 配置keepalive连接 其他模块见官方指导文档中的NGINX Modules由于本次搭建需要ssl等，编译安装命令如下： 1./configure --prefix=/usr/local/nginx --with-http_gzip_static_module --with-http_proxy_module --with-http_upstream_keepalive_module --with-file-aio --with-http_ssl_module --with-http_v2_module --with-pcre=../pcre-8.40 --with-zlib=../zlib-1.2.11 当执行./configure 命令报./configure: error: invalid option “–with-http_gzip_module”选项不可用时，可以通过./configure –help查看支持的选项，,修改上面的命令： 1234567891011./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-stream --with-pcre=../pcre-8.40 --with-zlib=../zlib-1.2.11 --with-openssl=../openssl-1.0.2fmake &amp;&amp; make install#编译完之后启动nginx，进入sbin目录启动nginxnginx#启动完之后通过curl测试是否启动成功curl http://localhost#nginx 重启/配置文件验证等命令：sbin/nginx -t #验证配置文件sbin/nginx -s reload #重新加载sbin/nginx -c /usr/local/nginx/conf/nginx.conf #启动时指定配置文件]]></content>
      <categories>
        <category>服务器</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx安装</tag>
      </tags>
  </entry>
</search>
